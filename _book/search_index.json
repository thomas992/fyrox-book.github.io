[["index.html", "Fyrox Book Chapter 1 Fyrox Game Engine Book 1.1 Engine Version 1.2 How to read the book 1.3 API Documentation 1.4 Required knowledge 1.5 Support the development", " Fyrox Book Dmitry Stepanov 2024-06-20 Chapter 1 Fyrox Game Engine Book Practical reference and user guides for Fyrox Game Engine and its editor FyroxEd. ⚠️ Tip: If you want to start using the engine as fast as possible - read this chapter. Warning: The book is in early development stage, you can help to improve it by making a contribution in its repository. Don’t be shy, every tip is helpful! 1.1 Engine Version Fyrox Team is trying to keep the book up-to-date with the latest version from master branch. If something does not compile with the latest release from crates.io, then you need to use the latest engine from GitHub repo. 1.2 How to read the book Almost every chapter in this book can be read in any order, but we recommend reading Chapters 1, 2, 3 (they’re quite small) and then going through Platformer Tutorial (2D) while learning more about specific areas that interest you from the other chapters. There is also a First-Person Shooter Tutorial (3D) and RPG Tutorial (3D). 1.3 API Documentation The book is primarily focused on game development with Fyrox, not on its API. You can find API docs here. 1.4 Required knowledge We’re expecting that you know basics of Rust programming language, its package manager Cargo. It is also necessary to know the basics of the game development, linear algebra, principles of software development and patterns, otherwise the book will probably be very hard for you. 1.5 Support the development The future of the project fully depends on community support, every bit is important! "],["introduction.html", "Chapter 2 Introduction 2.1 Introduction to Fyrox 2.2 System Requirements 2.3 Basic concepts 2.4 Design Philosophy and Goals 2.5 Frequently Asked Questions", " Chapter 2 Introduction This section of the book contains brief overview of engine’s features, it should help you to decide if the engine suits your needs and will it be easy enough for you to use. Following chapters takes you into a tour over engine’s features, its editor, basic concepts and design philosophy. 2.1 Introduction to Fyrox Fyrox is a feature-rich, general purpose game engine that is suitable for any kind of games. It is capable to power games with small- or medium-sized worlds, large-sized world most likely will require some manual work. Games made with the engine are capable to run on desktop platforms (PC, Mac, Linux) and Web (WebAssembly). Mobile is planned for future releases. 2.1.1 What can the engine do? You can create pretty much any kind of game or interactive applications. Here’s some examples of what the engine can do: 2.1.2 How does the engine work? The engine consists of two parts that you’ll be actively using: the framework and the editor. The framework is a foundation of the engine, it manages rendering, sound, scripts, plugins, etc. While the editor contains lots of tools that can be used to create game worlds, manage assets, edit game objects, scripts and more. Fish Folly 2.1.3 Programming languages Everything of your game can be written entirely in Rust, utilizing its safety guarantees as well as speed. However, it is possible to use any scripting language you want, but that’s have no built-in support, and you need to implement this manually. 2.1.4 Engine Features This is a more or less complete (yet, it can be outdated) list of engine features: 2.1.4.1 General Exceptional safety, reliability, and speed. PC (Windows, Linux, macOS), Android, Web (WebAssembly) support. Modern, PBR rendering pipeline. Comprehensive documentation. Guide book 2D support. Integrated editor. Fast iterative compilation. Classic object-oriented design. Lots of examples. 2.1.4.2 Rendering Custom shaders, materials, and rendering techniques. Physically-based rendering. Metallic workflow. High dynamic range (HDR) rendering. Tone mapping. Color grading. Auto-exposure. Gamma correction. Deferred shading. Directional light. Point lights + shadows. Spotlights + shadows. Screen-Space Ambient Occlusion (SSAO). Soft shadows. Volumetric light (spot, point). Batching. Instancing. Fast Approximate Anti-Aliasing (FXAA). Normal mapping. Parallax mapping. Render in texture. Forward rendering for transparent objects. Sky box. Deferred decals. Multi-camera rendering. Lightmapping. Soft particles. Fully customizable vertex format. Compressed textures support. High-quality mip-map on-demand generation. 2.1.4.3 Scene Multiple scenes. Full-featured scene graph. Level-of-detail (LOD) support. GPU Skinning. Various scene nodes: Pivot. Camera. Decal. Mesh. Particle system. Sprite. Multilayer terrain. Rectangle (2D Sprites) Rigid body + Rigid Body 2D Collider + Collider 2D Joint + Joint 2D 2.1.4.4 Sound High quality binaural sound with HRTF support. Generic and spatial sound sources. Built-in streaming for large sounds. Raw samples playback support. WAV/OGG format support. HRTF support for excellent positioning and binaural effects. Reverb effect. 2.1.4.5 Serialization Powerful serialization system Almost every entity of the engine can be serialized No need to write your own serialization. 2.1.4.6 Animation Animation blending state machine - similar to Mecanim in Unity Engine. Animation retargetting - allows you to remap animation from one model to another. 2.1.4.7 Asset management Advanced asset manager. Fully asynchronous asset loading. PNG, JPG, TGA, DDS, etc. textures. FBX models loader. WAV, OGG sound formats. Compressed textures support (DXT1, DXT3, DTX5). 2.1.4.8 Artificial Intelligence (AI) A* pathfinder. Navmesh. Behavior trees. 2.1.4.9 User Interface (UI) Advanced node-based UI with lots of widgets More than 32 widgets Powerful layout system Full TTF/OTF fonts support Based on message passing Fully customizable GAPI-agnostic OS-agnostic Button widget Border widget Canvas widget Color picker widget Color field widget Check box widget Decorator widget. Drop-down list widget Grid widget Image widget List view widget Popup widget Progress bar widget Scroll bar widget Scroll panel widget Scroll viewer widget Stack panel widget Tab control widget Text widget Text box widget Tree widget Window widget File browser widget File selector widget Docking manager widget NumericUpDown widget Vector3&lt;f32&gt; editor widget Menu widget Menu item widget Message box widget Wrap panel widget Curve editor widget User defined widget 2.1.4.10 Physics Advanced physics (thanks to the Rapier physics engine) Rigid bodies. Rich set of various colliders. Joints. Ray cast. Many other useful features. 2D support. 2.2 System Requirements As any other software, Fyrox has its own system requirements that will provide the best user experience. CPU - at least 2 core CPU with 1.5 GHz per each core. The more is better. GPU - any relatively modern GPU with OpenGL 3.3+ support. If the editor fails to start, then it is most likely your video card does not support OpenGL 3.3+. Do not try to run the editor on virtual machines, pretty much all of them have rudimentary support for graphics APIs which won’t let you run the editor. RAM - at least 1 Gb of RAM. The more is better. VRAM - at least 256 Mb of video memory. It highly depends on your game. 2.2.1 Supported Platforms Platform Engine Editor Windows ✅ ✅ Linux ✅ ✅ macOS ✅¹ ✅ WebAssembly ✅ ❌² Android ✅ ❌² ✅ - first-class support ❌ - not supported ¹ - macOS suffers from bad GPU performance on Intel chipsets, M1+ works well. ² - the editor works only on PC, it requires rich filesystem functionality as well as decent threading support. 2.3 Basic concepts Let’s briefly get over some basic concepts of the engine, there’s not much, but all of them are crucial to understand design decisions made in the engine. 2.3.1 Classic OOP The engine uses somewhat classic OOP with composition over inheritance - complex objects in the engine can be constructed using simpler objects. 2.3.2 Scenes In Fyrox, you break down your game in a set of reusable scenes. Pretty much anything can be a scene: a player, a weapon, a bot, level parts, etc. Scenes can be nested one into another, this helps you to break down complex scenes into reusable parts. Scene in Fyrox is also plays a role of prefab, there’s pretty much no difference between them. 2.3.3 Nodes and Scene Graph A scene is made of one or more nodes (every scene must have at least one root node, to which everything else is attached). Scene node contains specific set of properties as well as one optional script instance which is responsible for custom game logic. Typical structure of a scene node could be represented by the following example. The base object for every scene node is a Base node, it contains a transform, a list of children, etc. A more complex node, that extends functionality of the Base node stores an instance of Base inside of them. For example, a Mesh node is a Base node plus some specific info (a list of surfaces, material, etc.). The “hierarchy” depth is unlimited - a Light node in the engine is an enumeration of three possible types of light source. Directional, Point, and Spot light sources both use BaseLight node, which in its turn contains Base node inside. Graphically it can be represented like so: `Point` |__ Point Light Properties (radius, etc.) |__`BaseLight` |__ Base Light Properties (color, etc.) |__`Base` |__ Base Node Properties (transform, children nodes, etc.) As you can see, this forms the nice tree (graph) that shows what the object contains. This is very natural way of describing scene nodes, it gives you the full power of building an object of any complexity. 2.3.4 Plugins Plugin is a container for “global” game data and logic, its main usage is to provide scripts with some data and to manage global game state. 2.3.5 Scripts Script - is a separate piece of data and logic, that can be attached to scene nodes. This is primary (but not single) way of adding custom game logic. 2.4 Design Philosophy and Goals Let’s talk a bit about design philosophy and goals of the engine. Development of the engine started in the beginning of 2019 as a hobby project to learn Rust, and it quickly showed that Rust can be a game changer in the game development industry. Initially, the engine was just a port of an engine that is written in C. At the beginning, it was very interesting to build such complex thing as game engine in such low level language without any safety guarantees. After a year of development it became annoying to fix memory related issues (memory corruption, leaks, etc.), luckily at that time Rust’s popularity grew, and it showed on my radar. I ((mrDIMAS?)) was able to port the engine to it in less than a year. Stability has improved dramatically, no more random crashes, performance was at the same or better levels - time invested in learning new language was paid off. Development speed does not degrade over time as it was in C, it is very easy to manage growing project. 2.4.1 Safety One of the main goals in the development of the engine is to provide a high level of safety. What does this mean? In short: protection from memory-safety related bugs. This does not include any logic errors, but when your game is free of random crashes due to memory unsafety it is much easier to fix logic bugs, because you don’t have to think about potentially corrupted memory. Safety also dictates the architectural design decisions of your game. The typical callback hell, that is possible to do in many other languages, is very tedious to implement in Rust. It is possible, but it requires quite a lot of manual work which quickly tells you that you’re doing it wrong. 2.4.2 Performance Game engines are usually built using system-level programming languages, which provide peak performance levels. Fyrox is not an exception. One of its design goals is to provide high levels of performance by default, leaving an opportunity for adding custom solutions for performance-critical places. 2.4.3 Ease of use Another very important part is that the engine should be friendly to newcomers. It should lower the entry threshold, not make it worse. Fyrox uses well known and battle-tested concepts, thus making it easier to make games with it. On the other hand, it can still be extended with anything you need - it tries to be as good for veterans of the game industry as it is for newcomers. 2.4.4 Battle-tested Fyrox has large projects built on it, which helps with understanding the real needs of a general-purpose game engine. It also helps reveal weak spots in the design and fix them. 2.5 Frequently Asked Questions This chapter contains answers for frequently asked questions. 2.5.1 Which graphics API does the engine use? Fyrox uses OpenGL 3.3 on PC and OpenGL ES 3.0 on WebAssembly. Why? Mainly due to historical reasons. Back in the day (Q4 of 2018), there weren’t any good alternatives to it with a wide range of supported platforms. For example, wgpu didn’t even exist, as its first version was released in January 2019. Other crates were taking their first baby steps and weren’t ready for production. 2.5.1.1 Why not use alternatives now? There is no need for it. The current implementation works and is more than good enough. So instead of focusing on replacing something that works for little to no benefit, the current focus is on adding features that are missing as well as improving existing features when needed. 2.5.2 Is the engine based on ECS? No, the engine uses a mixed composition-based, object-oriented design with message passing and other different approaches that fit the most for a particular task. Why not use ECS for everything, though? Pragmatism. Use the right tool for the job. Don’t use a microscope to hammer nails. 2.5.3 What kinds of games can I make using Fyrox? Pretty much any kind of games, except maybe games with vast open-worlds (since there’s no built-in world streaming). In general, it depends on your game development experience. "],["getting-started.html", "Chapter 3 Getting Started 3.1 Editor, Plugins and Scripts 3.2 Code Hot Reloading 3.3 FyroxEd Overview 3.4 Scene and Scene Graph 3.5 Assets 3.6 Data Management 3.7 Borrow Checker", " Chapter 3 Getting Started This section of the book will guide you through the basics of the engine. You will learn how to create a project, use plugins, scripts, assets, and the editor. Fyrox is a modern game engine with its own scene editor, that helps you to edit game worlds, manage assets, and many more. At the end of reading this section, you’ll also learn how to manage game and engine entities, how they’re structured and what are the basics of data management in the engine. Next chapter will guide you through major setup of the engine - creating a game project using special project generator tool. 3.1 Editor, Plugins and Scripts Every Fyrox game is just a plugin for both the engine and the editor, such approach allows the game to run from the editor and be able to edit the game entities in it. A game can define any number of scripts, which can be assigned to scene objects to run custom game logic on them. This chapter will cover how to install the engine with its platform-specific dependencies, how to use the plugins and scripting system, how to run the editor. 3.1.1 Platform-specific Dependencies Before starting to use the engine, make sure all required platform-specific development dependencies are installed. If using Windows or macOS, no additional dependencies are required other than the latest Rust installed with appropriate toolchain for your platform. 3.1.1.1 Linux On Linux, Fyrox needs the following libraries for development: libxcb-shape0, libxcb-xfixes0, libxcb1, libxkbcommon, libasound2 and the build-essential package group. For Debian based distros like Ubuntu, they can be installed like below: sudo apt install libxcb-shape0-dev libxcb-xfixes0-dev libxcb1-dev libxkbcommon-dev libasound2-dev build-essential For NixOS, you can use a shell.nix like below: { pkgs ? import &lt;nixpkgs&gt; { } }: pkgs.mkShell rec { nativeBuildInputs = with pkgs.buildPackages; [ pkg-config xorg.libxcb alsa-lib wayland libxkbcommon libGL ]; shellHook = with pkgs.lib; &#39;&#39; export LD_LIBRARY_PATH=${makeLibraryPath nativeBuildInputs}:/run/opengl-driver/lib:$LD_LIBRARY_PATH &#39;&#39;; } 3.1.2 Quick Start Run the following commands to start using the editor as quickly as possible. cargo install fyrox-template fyrox-template init --name fyrox_test --style 2d cd fyrox_test cargo run --package editor --release 3.1.3 Project Generator Fyrox plugins are written in Rust, this means that if the source code of the game changes one must recompile. This architecture requires some boilerplate code. Fyrox offers a special tiny command line tool - fyrox-template. It helps generate all this boilerplate with a single command. Install it by running the following command: cargo install fyrox-template Note for Linux: This installs it in $user/.cargo/bin. If receiving errors about the fyrox-template command not being found, add this hidden cargo bin folder to the operating systems $PATH environment variable. Now, navigate to the desired project folder and run the following command: fyrox-template init --name my_game --style 3d Note that unlike cargo init, this will create a new folder with the given name. The tool accepts two arguments - a project name (--name) and a style (--style), which defines the contents of the default scene. After initializing the project, go to game/src/lib.rs - this is where the game logic is located, as you can see, the fyrox-template generated quite a bit of code for you. There are comments explaining what each place is for. For more info about each method, please refer to the docs. Once the project is generated, memorize the two commands that will help run your game in different modes: cargo run --package editor --release - launches the editor with your game attached. The editor allows you to run your game from it and edit its game entities. It is intended to be used only for development. cargo run --package executor --release - creates and runs the production binary of your game, which can be shipped (for example - to a store). Navigate to your project’s directory and run cargo run --package editor --release, after some time you should see the editor: editor In the editor you can start building your game scene. Important note: your scene must have at least one camera, otherwise you won’t see a thing. Read the next chapter to learn how to use the editor. 3.1.4 Using the Latest Engine Version Due to the nature of the software development, some bugs will inevitably sneak into the major releases, due to this, you may want to use the latest engine version from the repository on GitHub, since it is the most likely to have bugs fixed (you can also contribute by fixing any bugs you find or at least, by filing an issue). 3.1.4.1 Automatic ⚠️ fyrox-template has special sub-command - upgrade to quickly upgrade to desired engine version. To upgrade to the latest version (nightly) you should execute fyrox-template upgrade --version nightly command in your game’s directory. There are three main variants for --version switch: nightly - uses latest nightly version of the engine from GitHub directly. This is the preferable version if you want to use the latest changes and bug fixes as they release. latest - uses latest stable version of the engine. This option also supports --local key, that sets the path to the engine to ../Fyrox/fyrox and the editor to ../Fyrox/editor. Obviously, such path requires the engine to be located in the parent directory of your project. This option could be useful if you want to use custom version of the engine (for example, if you’re developing a patch for the engine). major.minor.patch - uses specific stable version from crates.io (0.30.0 for example). 3.1.4.2 Manual Engine version can also be updated manually. The first step to take is to install the latest fyrox-template, this can be done with a single cargo command: cargo install fyrox-template --force --git https://github.com/FyroxEngine/Fyrox This will ensure you’re using the latest project/script template generator, which is important, since old versions of the template generator will most likely generate outdated code, no longer be compatible with the engine. To switch existing projects to the latest version of the engine, you need to specify paths pointing to the remote repository for the fyrox and fyroxed_base dependencies. You need to do this in the game, executor, and editor projects. First, open game/Cargo.toml and change the fyrox dependency to the following: [dependencies] fyrox = { git = &quot;https://github.com/FyroxEngine/Fyrox&quot; } Do the same for executor/Cargo.toml. The editor has two dependencies we need to change: fyrox and fyroxed_base. Open the editor/Cargo.toml and set both dependencies to the following: [dependencies] fyrox = { git = &quot;https://github.com/FyroxEngine/Fyrox&quot; } fyroxed_base = { git = &quot;https://github.com/FyroxEngine/Fyrox&quot; } Now your game will use the latest engine and editor, but beware - new commits could bring some API breaks. You can avoid these by specifying a particular commit, just add rev = \"desired_commit_hash\" to every dependency like so: [dependencies] fyrox = { git = &quot;https://github.com/FyroxEngine/Fyrox&quot;, rev = &quot;0195666b30562c1961a9808be38b5e5715da43af&quot; } fyroxed_base = { git = &quot;https://github.com/FyroxEngine/Fyrox&quot;, rev = &quot;0195666b30562c1961a9808be38b5e5715da43af&quot; } To bring a local git repository of the engine to being up-to-date, just call cargo update at the root of the project’s workspace. This will pull the latest changes from the remote, unless there is no rev specified. Learn more about dependency paths on the official cargo documentation, here. 3.1.5 Adding Game Logic Any object-specific game logic should be added using scripts. A script is a “container” for data and code, that will be executed by the engine. Read the Scripts chapter to learn how to create, edit, and use scripts in your game. 3.2 Code Hot Reloading Fyrox supports code hot reloading (CHR for short), which allows you to recompile the game code while the game is running. This functionality significantly reduces iteration times and allows rapid prototyping. This way, Rust becomes a sort of “scripting” language, but with all Rust safety and performance guarantees. CHR in action looks like this: 3.2.1 How To Use ⚠️ If you have an existing project from one of the previous versions of the engine, the best way to add support for CHR is to re-generate the entire project and copy all the assets and game code in the new project. CHR requires very specific project structure and a small mistake in it could lead to incorrect behavior. CHR is quite simple to use - a project generated by fyrox-template already has all that is needed for hot reloading. Yet, it requires some bootstrapping to start using it. At first, you need to compile your game plugin using the following command: RUSTFLAGS=&quot;-C prefer-dynamic=yes&quot; cargo build --package game_dylib --no-default-features --features=&quot;dylib-engine&quot; --profile dev-hot-reload This command will compile the engine DLL (fyrox_dylib.dll/so) and the plugin DLL (game_dylib.dll/so). Please note the mandatory environment variable RUSTFLAGS=\"-C prefer-dynamic=yes\". It forces the compiler to link standard library dynamically. It is very important, because if not set, the standard library will be duplicated in game plugin and engine, which will lead to subtle bugs. ⚠️ Environment variables can be set in a different ways, depending on your OS. On Linux it simply prepends the actual command, on Windows it requires a separate command. Other OSes can have their own ways of setting environment variables. The next step is to compile the editor in CHR mode. To do that, run the following command: RUSTFLAGS=&quot;-C prefer-dynamic=yes&quot; cargo run --package editor --no-default-features --features=&quot;dylib&quot; --profile dev-hot-reload This command will compile the editor in CHR mode and run it. After this, all you need to do is to select build profile in the editor to be Debug (HR): build_profile Once that’s done you can run your game by clicking on the green Play button. You can switch between CHR and normal mode (static linking) at any time. Keep in mind, that if you run the editor in CHR mode, it will also reload all changed plugins. 3.2.2 Build Profiles CHR uses separate build profiles: dev-hot-reload (no optimizations) and release-hot-reload (with optimizations). Separate build profiles allows you to quickly switch between statically linked plugins and code hot reloading. This could be useful if you’re experiencing some issues with hot reloading (see next section for more info). 3.2.3 Stability CHR is very new and experimental feature of the engine, it is based on wildly unsafe functionality which could result in memory corruption, subtle bugs, etc. If you experience weird behaviour of your game after hot reloading, run the game in normal (static linking) mode instead. Please report any bugs in the issue tracker of the engine. CHR was tested on two relatively large games - Fish Folly and Station Iapetus. You can download these projects and try CHR yourself. 3.2.4 Technical Details and Limitations CHR is using standard operating system (OS) mechanism of shared libraries (DLL for short). Pretty much any OS can load native code into a running process dynamically from a DLL. Any dynamically loaded library can then be unloaded from the process memory. This gives a perfect opportunity to reload game code in runtime. It may sound quite easy, but on practice there are a lot of issues. 3.2.4.1 Plugin Entities and Reloading Plugins can supply the engine with a predefined set of entities (such as scripts, etc.). These entities are serialized into a memory blob before the plugin itself is unloaded. When all plugins are reloaded, this memory blob is used to restore the state of plugin entities. That being said, pretty much all plugin entities must be serializable (implement Visit trait). 3.2.4.2 Trait Objects Trait object are very problematic with hot reloading, because internally trait objects contains vtable with function pointers. These pointers can be easily invalidated if the plugin is unloaded. This applies even to engine trait objects, if they’re created directly from the plugin side. The only way to bypass this issue is to use special methods from the engine to create its trait objects. It is possible to add a lint to clippy to check for such cases (see the respective issue). 3.2.4.3 Dangling Objects Current plugin system tries its best to remove all plugin’s entities from the engine internals before reloading plugins. However, some objects could be overlooked by this system, which could result in crash or memory corruption. Current approach of preventing to having dangling objects is based on built-in reflection system - the plugin system iterates across all fields of every object and checks its assembly name. If the assembly name match the plugin’s assembly name, then this object must be deleted before the plugin is unloaded. 3.2.4.4 Non-serializable Entities Not every object can be serialized, and in this case the current plugin system calls a special method to restore such non-serializable entities after hot reloading. Such entities could include server connections, job queues, etc. 3.3 FyroxEd Overview FyroxEd - is the native editor of Fyrox, it is made with one purpose - to be an integrated game development environment that helps you build your game from start to finish with relatively low effort. You’ll be spending a lot of time in the editor, so you should get familiar with it and learn how to use its basic functionalities. This chapter will guide you through the basics, advanced topics will be covered in their respective chapters. 3.3.1 Windows When you open the editor for the first time you may be confused by the amount of windows, buttons, lists, etc. you’ll be presented with. Each window serves a different purpose, but all of them work together to help you make your game. Let’s take a look at a screenshot of the editor and learn what each part of it is responsible for (please note that this can change over time, because development is quite fast and images can easily become outdated): Windows World viewer - shows every object in the scene and their relationships. Allows inspecting and editing the contents of the scene in a hierarchical form. Scene preview - renders the scene with debug info and various editor-specific objects (gizmos, entity icons, etc.). Allows you to select, move, rotate, scale, delete, etc. various entities. The Toolbar on its left side shows available context-dependent tools. Inspector - allows you to modify various properties of the selected object. Message Log - displays important messages from the editor. Navmesh Panel - allows you to create, delete, and edit navigational meshes. Command Stack - displays your most recent actions and allows you to undo or redo their changes. Asset Browser - allows you to inspect the assets of your game and to instantiate resources in the scene, among other things. Audio Context - allows you to edit the settings of the scene’s sound context (global volume, available audio buses, effects, etc.) 3.3.2 Creating or loading a Scene FyroxEd works with scenes - a scene is a container for game entities, you can create and edit one scene at a time. You must have a scene loaded to begin working with the editor. To create a scene go to File -&gt; New Scene. To load an existing scene, go to File -&gt; Load and select the desired scene through the file browser. Recently opened scenes can be loaded more quickly by going to File -&gt; Recent Scenes and selecting the desired one. 3.3.3 Populating a Scene A scene can contain various game entities. There are two equivalent ways of creating these: By going to Create in the main menu and selecting the desired entity from the drop down. By right-clicking on a game entity in the World Viewer and selecting the desired entity from the Create Child sub-menu. Complex objects usually made in 3D modelling software (Blender, 3Ds Max, Maya, etc.) can be saved in various formats. Fyrox supports FBX format, which is supported by pretty much any 3D modelling software. You can instantiate such objects by simply dragging the one you want and dropping it on the Scene Preview. While dragging it, you’ll also see a preview of the object. You can do the same with other scenes made in the editor (rgs files), for example, you can create a scene with a few objects in it with some scripts and re-use them within other scenes. Such scenes are called prefabs. 3.3.4 Saving a Scene To save your work, go to File -&gt; Save. If you’re saving a new scene, the editor will ask you to specify a file name and a path to where the scene will be saved. Scenes loaded from a file will automatically be saved to the path they were loaded from. 3.3.5 Undoing and redoing FyroxEd remembers your actions and allows you to undo and redo the changes done by these. You can undo or redo changes by either going to Edit -&gt; Undo/Redo or through the usual shortcuts: Ctrl+Z - to undo, Ctrl+Y - to redo. 3.3.6 Controls There are number of control keys that you’ll be using most of the time, pretty much all of them work in the Scene Preview window: 3.3.6.1 Editor camera movement Click and hold [Right Mouse Button] within the Scene Preview window to enable the movement controls: - [W][S][A][D] - Move camera forward/backward/left/right - [Space][Q]/[E] - Raise/Lower Camera - [Ctrl] - Speed up - [Shift]- Slowdown #### Others - [Left Mouse Button] - Select - [Middle Mouse Button] - Pan camera in viewing plane - [1] - Select interaction mode - [2] - Move interaction mode - [3] - Scale interaction mode - [4] - Rotate interaction mode - [5] - Navigational mesh editing mode - [6] - Terrain editing interaction mode - [Ctrl]+[Z] - Undo - [Ctrl]+[Y] - Redo - [Delete] - Delete current selection. 3.3.7 Play Mode One of the key features of the editor is that it allows you to run your game from it in a separate process. Use the Play/Stop button at the top of the Scene Preview window to enter or leave Play Mode. Keep in mind, that the editor UI will be locked while you’re in Play Mode. Play Mode can be activated only for projects made with the fyrox-template (or for projects with a similar structure). The editor calls cargo commands to build and run your game in a separate process. Running the game in a separate process ensures that the editor won’t crash if your game does, it also provides excellent isolation between the game and the editor, not giving a chance to break the editor by running the game. 3.3.8 Additional Utilities There are also number of powerful utilities that will make your life easier, they can be found under the Utils section of the main menu: Curve Editor - allows you to create and edit curve resources to make complex laws for game parameters. Path Fixer - helps you fix incorrect resource references in your scenes. 3.4 Scene and Scene Graph When you’re playing a game, you often see various objects scattered around the screen, all of them are forming a scene. A scene is just a set of a variety objects, as in many other game engines, Fyrox allows you to create multiple scenes for multiple purposes, for example, one scene could be used for a menu, a bunch of others for game levels, and another one for an ending screen. Scenes can also be used to create a source of data for other scenes, such scenes are called prefabs. Scenes can also be rendered in a texture, which can be used in other scenes - this way you can create interactive screens that show other places. While playing games, you may have noticed that some objects behaves as if they were linked to other objects, for example, a character in a role-playing game could carry a sword. While the character holds the sword, it is linked to his arm. Such relations between the objects can be presented by a graph structure. Simply speaking, a graph is a set of objects with hierarchical relationships between each object. Each object in the graph is called a node. In the example with the sword and the character, the sword is a child node of the character, and the character is a parent node of the sword (here we ignore the fact that in reality, character models usually contain complex skeletons, with the sword actually being attached to one of the hands’ bones, not to the character). You can change the hierarchy of nodes in the editor using a simple drag’n’drop functionality in the World Viewer - drag a node onto some other node, and it will attach itself to it. 3.4.1 Building Blocks or Scene Nodes The engine offers various types of “building blocks” for your scene, each such block is called a scene node. Base - stores hierarchical information (a handle to the parent node and handles to children nodes), local and global transform, name, tag, lifetime, etc. It has self-describing name - it’s used as a base node for every other scene node via composition. Mesh - represents a 3D model. This one of the most commonly used nodes in almost every game. Meshes can be easily created either programmatically, or be made in some 3D modelling software, such as Blender, and then loaded into the scene. Light - represents a light source. There are three types of light sources: Point - emits light in every direction. A real-world example would be a light bulb. Spot - emits light in a particular direction, with a cone-like shape. A real-world example would be a flashlight. Directional - emits light in a particular direction, but does not have position. The closest real-world example would be the Sun. Camera - allows you to see the world. You must have at least one camera in your scene to be able to see anything. Sprite - represents a quad that always faces towards a camera. It can have a texture and size and can also can be rotated around the “look” axis. Particle system - allows you to create visual effects using a huge set of small particles. It can be used to create smoke, sparks, blood splatters, etc. Terrain - allows you to create complex landscapes with minimal effort. Decal - paints on other nodes using a texture. It is used to simulate cracks in concrete walls, damaged parts of the road, blood splatters, bullet holes, etc. Rigid Body - a physical entity that is responsible for the dynamic of the rigid. There is a special variant for 2D - RigidBody2D. Collider - a physical shape for a rigid body. It is responsible for contact manifold generation, without it, any rigid body will not participate in simulation correctly, so every rigid body must have at least one collider. There is a special variant for 2D - Collider2D. Joint - a physical entity that restricts motion between two rigid bodies. It has various amounts of degrees of freedom depending on the type of the joint. There is a special variant for 2D - Joint2D. Rectangle - a simple rectangle mesh that can have a texture and a color. It is a very simple version of a Mesh node, yet it uses very optimized renderer, that allows you to render dozens of rectangles simultaneously. This node is intended for use in 2D games only. Sound - a sound source universal for 2D and 3D. Spatial blend factor allows you to select a proportion between 2D and 3D. Listener - an audio receiver that captures the sound at a particular point in your scene and sends it to an audio context for processing and outputting to an audio playback device. Animation Player - a container for multiple animations. It can play animations made in the animation editor and apply animation poses to respective scene nodes. Animation Blending State Machine - a state machine that mixes multiple animations from multiple states into one; each state is backed by one or more animation playing or blending nodes. See its respective chapter for more info. Every node can be created either in the editor (through Create on the main menu, or through Add Child after right-clicking on a game entity) or programmatically via their respective node builder (see API docs for more info). These scene nodes allow you to build almost any kind of game. It is also possible to create your own types of nodes, but that is an advanced topic, which is covered in a future chapter. 3.4.2 Local and Global Coordinates A graph describes your scene in a very natural way, allowing you think in terms of relative and absolute coordinates when working with scene nodes. A scene node has two kinds of transform - a local and global. The local transform defines where the node is located relative to its origin, its scale as a percentage, and its rotation around any arbitrary axis.The global transform is almost the same, but it also includes the whole chain of transforms of the parent nodes. Going back to the example of the character and the sword, if the character moves, and by extension the sword, the global transform of the sword will reflect the changes made to the character position, yet its local transform will not, since that represents the sword’s position’s relative to the character’s, which didn’t change. This mechanism is very simple, yet powerful. The full grace of it unfolds when you’re working with 3D models with skeletons. Each bone in a skeleton has its parent and a set of children, which allows you to rotate, translate, or scale them to animate your entire character. 3.5 Assets Pretty much every game depends on various assets, such as 3D models, textures, sounds, etc. Fyrox has its own assets pipeline made to make your life easier. 3.5.1 Asset Types The engine offers a set of assets that should cover all of your needs: Models - are a set of objects. They can be a simple 3D model (barrels, bushes, weapons, etc.) or complex scenes with lots of objects and possibly other model instances. Fyrox supports two main formats: FBX - which can be used to import 3D models, RGS - which are scenes made in FyroxEd. RGS models are special, as they can be used as hierarchical prefabs. Textures - are images used to add graphical details to objects. The engine supports multiple texture formats, such as PNG, JPG, BMP, etc. Compressed textures in DDS format are also supported. Sound buffers - are data buffers for sound sources. Fyrox supports WAV and OGG formats. Curves - are parametric curves. They’re used to create complex functions for numeric parameters. They can be made in the Curve Editor (Utils -&gt; Curve Editor) HRIR Spheres - head-related impulse response collection used for head-related transfer function in the HRTF sound rendering. Fonts - arbitrary TTF/OTF fonts. Materials - materials for rendering. Shaders - shaders for rendering. It is also possible to create custom assets. See respective chapter for more info. 3.5.2 Asset Management Asset management is performed from the Asset Browser window in the editor, you can select an asset, preview it, and edit its import options. Here’s a screenshot of the asset browser with a texture selected: asset browser The most interesting part here is the import options section under the previewer. It allows you to set asset-specific import options and apply them. Every asset has its own set of import options. See their respective asset page from the section above to learn what each import option is for. 3.5.3 Asset Instantiation Some asset types can be instantiated in scenes; for now, you can only create direct instances from models. This is done by simply dragging the model you want to instantiate and dropping it on the Scene Preview. While dragging it, you’ll also see a preview of the model. preview The maximum amount of asset instances is not limited by the engine but it is by the memory and CPU resources of your PC. Note that the engine does try to reuse data across instances as much as possible. You can also instantiate assets dynamically from your code. Here’s an example of that for a Model: {{#include ../code/snippets/src/resource/mod.rs:instantiate_model}} This is very useful with prefabs that you may want to instantiate in a scene at runtime. 3.5.4 Loading Assets Usually, there is no need to manually handle the loading of assets since you have the editor to help with that - just create a scene with all the required assets. However, there are times when you may need to instantiate some asset dynamically, for example, a bot prefab. For these cases, you can use the ResourceManager::request&lt;T&gt; method with the appropriate type, such as Model, Texture, SoundBuffer, etc. 3.6 Data Management The engine uses pools to store most objects (scene nodes in a graph, animations in an animation player, sound sources in an audio context, etc.). Since you’ll use them quite often, reading and understanding this chapter is recommended. 3.6.1 Motivation Rust ownership system and borrow checker, in particular, dictate the rules of data management. In game development, you often have the need to reference objects from other objects. In languages like C, this is usually achieved by simply storing a raw pointer and calling it a day. That works, yet it’s remarkably unsafe - you risk either forgetting to destroy an object and leaking memory or destroying an object still being referenced and then trying to access deallocated memory. Other languages, like C++, allow you to store shared pointers to your data, which by keeping a reference count, ensures the previous doesn’t happen at the cost of a, most often, negligible overhead. Rust counts with smart pointers similar to this, though not without their limitations. There is the Rc/Arc - they function like shared pointers, except they don’t allow mutating their content, only reading it. If you want mutability, you use either a RefCell for a single-threaded environment, or a Mutex for a multithreaded environment. That is where the problems begin. For types such as Rc&lt;RefCell&gt; or Arc&lt;Mutex&gt;, Rust enforces its borrowing rules at runtime, which are unlimited readers but a single writer. Any attempt to borrow mutably more than once at a time will lead to a runtime error. Another problem with these shared references is that is very easy to accidentally create cyclical references that prevent objects from ever being destroyed. While the previous could be lived with, the last problem is especially severe in the case of games: the overhead of runtime checks. In the case of a Rc&lt;RefCell&gt;, it is a single reference counter for given accesses to the data, but in the case of a Arc&lt;Mutex&gt;, it is a mutex lock. The solution to these problems is far from ideal; it certainly has its own downfalls. Instead of scattering objects across memory and then having to manage the lifetime of each of them through reference counting, we can store all of the objects in a single and contiguous memory block and then use indices to access each object. Such a structure is called a pool. 3.6.2 Technical Details A pool is an efficient method of data management. A pool is a vector with entries that can be either vacant or occupied. Each entry, regardless of its status, also stores a number called a generation number. This is used to understand whether an entry has changed over time or not. When an entry is reused, its generation number is increased, rendering all previously created handles leading to the entry invalid. This is a simple and efficient algorithm for tracking the lifetime of objects. To access the data in the entries, the engine uses the previously mentioned handles. A handle is a pair of the index of an entry and a generation number. When you put an object in the pool, this gives you the handle that leads to the object, as well as the entry’s current generation number. The number remains valid until you “free” the object, which makes the entry vacant again. 3.6.3 Advantages Since a pool is a contiguous memory block, it is far more CPU cache-friendly. This reduces the occurrences of CPU cache misses, which makes accesses to data blazingly fast. Almost every entity in Fyrox lives on its own pool, which makes it easy to create data structures like graphs, where nodes refer to other nodes. In this case, nodes simply need to store a handle to refer to other nodes. Simple lifetime management. There is no way to leak memory since cross-references can only be done via handles. Fast random access with a constant complexity. Handles are the same size as a pointer on a 64-bit architecture, just 8 bytes. 3.6.4 Disadvantages Pools can contain lots of gaps between currently used memory, which may lead to less efficient memory usage. Handles are sort of weak references, but worse. Since they do not own any data nor even point to their data, you need a reference to its pool instance in order to borrow the data a handle leads to. Handles introduce a level of indirection that can hurt performance in places with high loads that require random access, though this is not too significant as random access is already somewhat slow because of potential CPU cache misses. 3.6.5 Usage You’ll use Handle a lot while working with Fyrox. So where are the main usages of pools and handles? The largest is in a scene graph. This stores all the nodes in a pool and gives handles to each node. Each scene node stores a handle to their parent node and a set of handles to their children nodes. A scene graph automatically ensures that such handles are valid. In scripts, you can also store handles to scene nodes and assign them in the editor. Animation is another place that stores handles to animated scene nodes. Animation Blending State Machine stores its own state graph using a pool; it also takes handles to animations from an animation player in a scene. And the list could keep going for a long time. This is why you need to understand the basic concepts of data management, as to efficiently and fearlessly use Fyrox. 3.6.6 Borrowing Once an object is placed in a pool, you have to use its respective handle to get a reference to it. This can be done with either pool.borrow(handle) or pool.borrow_mute(handle), or by using the Index trait: pool[handle]. Note that these methods panic when the handle given is invalid. If you want to be safe, use the try_borrow(handle) or try_borrow_mut(handle) method. # extern crate fyrox; # use fyrox::core::pool::Pool; # # fn main() { let mut pool = Pool::&lt;u32&gt;::new(); let handle = pool.spawn(1); let obj = pool.borrow_mut(handle); *obj = 11; let obj = pool.borrow(handle); assert_eq!(*obj, 11); # } 3.6.7 Freeing You can extract an object from a pool by calling pool.free(handle). This will give you the object back and make all current handles to it invalid. # extern crate fyrox; # use fyrox::core::pool::Pool; # # fn main() { let mut pool = Pool::&lt;u32&gt;::new(); let handle = pool.spawn(1); pool.free(handle); let obj = pool.try_borrow(handle); assert_eq!(obj, None); # } 3.6.8 Take and Reserve Sometimes you may want to temporarily extract an object from a pool, do something with it, and then put it back, yet not want to break every handle to the object in the process. There are three methods for this: take_reserve + try_take_reserve - moves an object out of the pool but leaves the entry in an occupied state. This function returns a tuple with two values (Ticket&lt;T&gt;, T). The latter one being your object, and the former one being a wrapper over its index that allows you to return the object once you’re done with it. This is called a ticket. Note that attempting to borrow a moved object will cause a panic! put_back - moves the object back using the given ticket. The ticket contains information about where in the pool to return the object to. forget_ticket - makes the pool entry vacant again. Useful in cases where you move an object out of the pool, and then decide you won’t return it. If this is the case, you must call this method, otherwise, the corresponding entry will remain unusable. Reservation example: # extern crate fyrox; # use fyrox::core::pool::Pool; # # fn main() { let mut pool = Pool::&lt;u32&gt;::new(); let handle = pool.spawn(1); let (ticket, ref mut obj) = pool.take_reserve(handle); *obj = 123; // Attempting to fetch while there is an existing reservation, will fail. let attempt_obj = pool.try_borrow(handle); assert_eq!(attempt_obj, None); // Put the object back, allowing borrowing again. pool.put_back(ticket, *obj); let obj = pool.borrow(handle); assert_eq!(obj, &amp;123); # } Forget example: # extern crate fyrox; # use fyrox::core::pool::Pool; # # fn main() { let mut pool = Pool::&lt;u32&gt;::new(); let handle = pool.spawn(1); let (ticket, _obj) = pool.take_reserve(handle); pool.forget_ticket(ticket); let obj = pool.try_borrow(handle); assert_eq!(obj, None); # } 3.6.9 Iterators There are a few possible iterators, each one serving its own purpose: iter/iter_mut - creates an iterator over occupied pool entries, returning references to each object. pair_iter/pair_iter_mut - creates an iterator over occupied pool entries, returning tuples of a handle and reference to each object. # extern crate fyrox; # use fyrox::core::pool::Pool; # # fn main() { let mut pool = Pool::&lt;u32&gt;::new(); let _handle = pool.spawn(1); let mut iter = pool.iter_mut(); let next_obj = iter.next().unwrap(); assert_eq!(next_obj, &amp;1); let next_obj = iter.next(); assert_eq!(next_obj, None); # } 3.6.10 Direct Access You have the ability to get an object from a pool using only an index. The methods for that are at and at_mut. 3.6.11 Validation To check if a handle is valid, you can use the is_valid_handle method. 3.6.12 Type-erased Handles The pool module also offers type-erased handles that can be of use in some situations. Still, try to avoid using these, as they may introduce hard-to-reproduce bugs. Type safety is always good :3 A type-erased handle is called an ErasedHandle and can be created either manually or from a strongly-typed handle. Both handle types are interchangeable; you can use the From and Into traits to convert from one to the other. 3.6.12.1 Getting a Handle to an Object by its Reference If you need to get a handle to an object from only having a reference to it, you can use the handle_of method. 3.6.12.2 Iterate Over and Filter Out Objects The retain method allows you to filter your pool’s content using a closure provided by you. 3.7 Borrow Checker Rust has a famous borrow checker, that became a sort of horror story for newcomers. It usually treated like an enemy, that prevents your from writing anything useful as you may get used in other languages. In fact, it is a very useful part of Rust that proves correctness of your program and does not let you doing nasty things like memory corruption, data races, etc. This chapter explains how Fyrox solves the most common borrowing issues and makes game development as easy as in any other game engine. 3.7.1 Multiple Borrowing When writing a script logic there is often a need to do a multiple borrowing of some data, usually it is other scene nodes. In normal circumstances you can borrow each node one-by-one, but in other cases you can’t do an action without borrowing two or more nodes simultaneously. In this case you can use multi-borrowing: {{#include ../code/snippets/src/borrowck/mod.rs:synthetic_example}} As you can see, you can borrow multiple nodes at once with no compilation errors. Borrowing rules in this case are enforced at runtime. They’re the same as standard Rust borrowing rules: You can have infinite number of immutable references to the same object. You can have only one mutable reference to the same object. Multi-borrow context provides detailed error messages for cases when borrowing has failed. For example, it will tell you if you’re trying to mutably borrow an object, that was already borrowed as immutable (and vice versa). It also provides handle validation and will tell you what’s wrong with it. It could be either invalid index of it, or the generation. The latter means that the object at the handle was changed and the handle is invalid. The previous example looks kinda synthetic and does not show the real-world code that could lead to borrowing issues. Let’s fix this. Imagine that you’re making a shooter, and you have bots, that can follow and attack targets. Then the code could look like this: {{#include ../code/snippets/src/borrowck/mod.rs:bot_example}} As you can see, for this code to compile we need to borrow at least two nodes simultaneously: the node with Bot script and the target node. This is because we’re calculating distance between the two nodes to switch animations accordingly (attack if the target is close enough). As pretty much any approach, this one is not ideal and comes with its own pros and cons. The pros are quite simple: No compilation errors - sometimes Rust is too strict about borrowing rules, and valid code does not pass its checks. Better ergonomics - no need to juggle with temporary variable here and there to perform an action. The cons are: Multi-borrowing is slightly slower (~1-4% depending on your use case) - this happens because the multi-borrowing context checks borrowing rules at runtime. 3.7.2 Message Passing Sometimes the code becomes so convoluted, so it is simply hard to maintain and understand what it is doing. This happens when code coupling get to a certain point, which requires very broad context for the code to be executed. For example, if bots in your game have weapons it is so tempting to just borrow the weapon and call something like weapon.shoot(..). When your weapon is simple then it might work fine, however when your game gets bigger and weapons get new features simple weapon.shoot(..) could be not enough. It could be because shoot method get more and more arguments or by some other reason. This is quite common case and in general when your code become tightly coupled it becomes hard to maintain it and what’s more important - it could easily result in compilation errors, that comes from borrow checker. To illustrate this, let’s look at this code: {{#include ../code/snippets/src/borrowck/without_message_passing.rs:without_message_passing}} This is probably one of the typical implementations of shooting in games - you cast a ray from the weapon and if it hits a bot, you’re applying some damage to it. In this case bots can also shoot, and this is where borrow checker again gets in our way. If you try to uncomment the // weapon.shoot(ctx.handle, &amp;mut ctx.scene.graph); line you’ll get a compilation error, that tells you that ctx.scene.graph is already borrowed. It seems that we’ve stuck, and we need to somehow fix this issue. We can’t use multi-borrowing in this case, because it still enforces borrowing rules and instead of compilation error, you’ll runtime error. To solve this, you can use well-known message passing mechanism. The core idea of it is to not call methods immediately, but to collect all the needed data for the call and send it an object, so it can do the call later. Here’s how it will look: {{#include ../code/snippets/src/borrowck/message_passing.rs:message_passing}} The weapon now subscribes to ShootMessage and listens to it in on_message method and from there it can perform the actual shooting without any borrowing issues. The bot now just sends the ShootMessage instead of borrowing the weapon trying to call shoot directly. The messages do not add any one-frame delay as you might think, they’re processed in the same frame so there’s no one-or-more frames desynchronization. This approach with messages has its own pros and cons. The pros are quite significant: Decoupling - coupling is now very loose and done mostly on message side. Easy to refactor - since the coupling is loose, you can refactor the internals with low chance of breaking existing code, that could otherwise be done because of intertwined and convoluted code. No borrowing issues - the method calls are done in different places and there’s no lifetime collisions. Easy to write unit and integration tests - this comes from loose coupling. The cons are the following: Message passing is slightly slower than direct method calls (~1-7% depending on your use case) - you should keep message granularity at a reasonable level. Do not use message passing for tiny changes, it will most likely make your game slower. "],["scripting.html", "Chapter 4 Scripting 4.1 Plugins 4.2 Executor 4.3 Scripts 4.4 Tasks", " Chapter 4 Scripting A game based on Fyrox is a plugin to the engine and the editor. Plugin defines global application logic and can provide a set of scripts, that can be used to assign custom logic to scene nodes. Every script can be attached to only one plugin. Fyrox uses scripts to create custom game logic, scripts can be written only in Rust which ensures that your game will be crash-free, fast and easy to refactor. Next chapters will cover all parts and will help you to learn how to use plugins + scripts correctly. 4.1 Plugins A game based on Fyrox is a plugin to the engine and the editor. Plugin defines global application logic and provides a set of scripts, that can be used to assign custom logic to scene nodes. Plugin is an “entry point” of your game, it has a fixed set of methods that can be used for initialization, update, OS event handling, etc. Every plugin could be linked to the engine (and the editor) in two ways: statically or dynamically using hot reloading. Code hot reloading is usually used for development purposes only. The main purpose of the plugins is to hold and operate on some global application data, that can be used in scripts and provide a set of scripts to the engine. Plugins also have much wider access to engine internals, than scripts. For example, it is possible to change scenes, add render passes, change resolution, etc. which is not possible from scripts. 4.1.1 Structure Plugin structure is defined by Plugin trait. Typical implementation can be generated by fyrox-template tool, and it looks something like this: {{#include ../code/snippets/src/scripting/plugin.rs:plugin_structure}} As you can see, the game structure (struct Game) implements a bunch of traits. Reflect - is needed for static reflection to inspect the content of the plugin. Visit - is mostly needed for hot reloading, to save/load the content of the plugin. Default - provides sensible default state of the game. Plugin trait is very special - it can execute the actual game logic in one of its methods: register - called once on start allowing you to register your scripts. Important: You must register all your scripts here, otherwise the engine (and the editor) will know nothing about them. Also, you should register loaders for your custom resources here. See Custom Resource chapter more info. init - called once when the plugin registers in the engine. This method allows you to initialize the game into some sensible state. Keep in mind, that the editor will not call this method, it does not create any game instance. The method has scene_path parameter, in short it is a path to a scene that is currently opened in the editor (it will be None if either there’s no opened scene or your game was started outside the editor). It is described in Editor and Plugins section down below. on_deinit - it is called when the game is about to shut down. Can be used for any clean up, for example logging that the game has closed. update - it is called each frame at a stable rate (usually 60 Hz, but can be configured in the Executor) after the plugin is created and fully initialized. It is the main place where you should put object-independent game logic (such as user interface handling, global application state management, etc.), any other logic should be added via scripts. on_os_event - it is called when the main application window receives an event from the operating system, it can be any event such as keyboard, mouse, game pad events or any other events. Please note that as for update method, you should put here only object-independent logic. Scripts can catch OS events too. on_ui_message - it is called when there is a message from the user interface, it should be used to react to user actions (like pressed buttons, etc.) on_graphics_context_initialized - it is called when a graphics context was successfully initialized. This method could be used to access the renderer (to change its quality settings, for instance). You can also access a main window instance and change its properties (such as title, size, resolution, etc.). on_graphics_context_destroyed - it is called when the current graphics context was destroyed. It could happen on a small number of platforms, such as Android. Such platforms usually have some sort of suspension mode, in which you are not allowed to render graphics, to have a “window”, etc. before_rendering - it is called when the engine is about to render a new frame. This method is useful to perform offscreen rendering (for example - user interface). on_scene_begin_loading - it is called when the engine starts to load a game scene. This method could be used to show a progress bar or some sort of loading screen, etc. on_scene_loaded - it is called when the engine successfully loaded a game scene. This method could be used to add custom logic to do something with a newly loaded scene. 4.1.2 Plugin Context Vast majority of methods accept PluginContext - it provides almost full access to engine entities, it has access to the renderer, scenes container, resource manager, user interface, main application window. Typical content of the context is something like this: {{#include ../code/snippets/src/scripting/context.rs:plugin_context}} scenes - a scene container, could be used to manage game scenes - add, remove, borrow. An example of scene loading is given in the previous code snippet in Game::new() method. resource_manager - is used to load external resources (scenes, models, textures, animations, sound buffers, etc.) from different sources (disk, network storage on WebAssembly, etc.) user_interfaces - use it to create user interface for your game, the interface is scene-independent and will remain the same even if there are multiple scenes created. There’s always at least one user interface created, it can be accessed using .first()/first_mut() methods. The engine support unlimited instances of user interfaces. graphics_context - a reference to the graphics_context, it contains a reference to the window and the current renderer. It could be GraphicsContext::Uninitialized if your application is suspended (possible only on Android). dt - a time passed since the last frame. The actual value is implementation-defined, but on current implementation it is equal to 1/60 of a second and does not change event if the frame rate is changing (the engine stabilizes update rate for the logic). lag - a reference to the time accumulator, that holds remaining amount of time that should be used to update a plugin. A caller splits lag into multiple sub-steps using dt and thus stabilizes update rate. The main use of this variable, is to be able to reset lag when you’re doing some heavy calculations in a game loop (i.e. loading a new level) so the engine won’t try to “catch up” with all the time that was spent in heavy calculation. serialization_context - it can be used to register scripts and custom scene nodes constructors at runtime. widget_constructors - it can be used to register custom widgets. performance_statistics - performance statistics from the last frame. To get a rendering performance statistics, use Renderer::get_statistics method, that could be obtained from the renderer instance in the current graphics context. elapsed_time - amount of time (in seconds) that passed from creation of the engine. Keep in mind, that this value is not guaranteed to match real time. A user can change delta time with which the engine “ticks” and this delta time affects elapsed time. script_processor - a reference to the current script processor instance, which could be used to access a list of scenes that supports scripts. async_scene_loader - a reference to the current asynchronous scene loader instance. It could be used to request a new scene to be loaded. window_target - special field that associates main application event loop (not game loop) with OS-specific windows. It also can be used to alternate control flow of the application. task_pool - task pool for asynchronous task management. 4.1.3 Control Flow Plugin context provides access to a special variable window_target, which could be used to alternate control flow of the application. The most common use of it is to close the game by calling window_target.unwrap().exit() method. Notice the unwrap() here, window_target could not be available at all times. Ideally you should do checked access here. 4.1.4 Editor and Plugins When you’re running your game from the editor, it starts the game as a separate process and if there’s a scene opened in the editor, it tells the game instance to load it on startup. Let’s look closely at Plugin::init method: {{#include ../code/snippets/src/scripting/plugin.rs:plugin_init}} The scene_path parameter is a path to a scene that is currently opened in the editor, your game should use it if you need to load a currently selected scene of the editor in your game. However, it is not strictly necessary - you may desire to start your game from a specific scene all the time, even when the game starts from the editor. If the parameter is None, then there is no scene loaded in the editor or the game was run outside the editor. 4.2 Executor Executor is a simple wrapper that drives your game plugins, it is intended to be used for production builds of your game. The editor runs the executor in separate process when you’re entering the play mode. Basically, there is no significant difference between running the game from the editor, or running it as a separate application. The main difference is that the editor passes scene_path parameter for the executor when entering the play mode. 4.2.1 Usage Executor is meant to be a part of your project’s workspace, its typical look could something like this: # extern crate fyrox; # use fyrox::{ # core::{pool::Handle, uuid::Uuid}, # engine::executor::Executor, # plugin::{Plugin, PluginConstructor, PluginContext}, # scene::{Scene}, # }; # struct GameConstructor; # impl PluginConstructor for GameConstructor { # fn create_instance( # &amp;self, # _scene_path: Option&lt;&amp;str&gt;, # _context: PluginContext, # ) -&gt; Box&lt;dyn Plugin&gt; { # todo!() # } # } fn main() { let mut executor = Executor::new(); // Register your game constructor here. executor.add_plugin_constructor(GameConstructor); executor.run() } Executor has full access to the engine, and through it to the main application window. You can freely change desired parts, Executor implements Deref&lt;Target = Engine&gt; + DerefMut traits, so you can use its instance as an “alias” to engine instance. To add a plugin to the executor, just use add_plugin_constructor method, it accepts any entity that implements PluginConstructor traits. 4.2.2 Typical Use Cases This section covers typical use cases for the Executor. 4.2.2.1 Setting Window Title You can set window title when creating executor instance: # extern crate fyrox; # use fyrox::engine::executor::Executor; # use fyrox::window::WindowAttributes; # use fyrox::engine::GraphicsContextParams; # use fyrox::event_loop::EventLoop; let executor = Executor::from_params( EventLoop::new().unwrap(), GraphicsContextParams { window_attributes: WindowAttributes { title: &quot;My Game&quot;.to_string(), ..Default::default() }, vsync: true, }, ); 4.3 Scripts Script - is a container for game data and logic that can be assigned to a scene node. Fyrox uses Rust for scripting, so scripts are as fast as native code. Every scene node can have any number of scripts assigned. 4.3.1 When to Use Scripts and When Not Scripts are meant to be used to add data and some logic to scene nodes. That being said, you should not use scripts to hold some global state of your game (use your game plugin for that). For example, use scripts for your game items, bots, player, level, etc. On the other hand do not use scripts for leader boards, game menus, progress information, etc. Also, scripts cannot be assigned to UI widgets due to intentional Game &lt;-&gt; UI decoupling reasons. All user interface components should be created and handled in the game plugin of your game. 4.3.2 Script Structure Typical script structure is something like this: {{#include ../code/snippets/src/scripting/example.rs:example_script}} Each script must implement following traits: Visit implements serialization/deserialization functionality, it is used by the editor to save your object to a scene file. Reflect implements compile-time reflection that provides a way to iterate over script fields, set their values, find fields by their paths, etc. Debug - provides debugging functionality, it is mostly for the editor to let it turn the structure and its fields into string. Clone - makes your structure clone-able, since we can clone objects, we also want the script instance to be cloned. Default implementation is very important - the scripting system uses it to create your scripts in the default state. This is necessary to set some data to it and so on. If it’s a special case, you can always implement your own Default’s implementation if it’s necessary for your script. TypeUuidProvider is used to attach some unique id for your type, every script must have a unique ID, otherwise, the engine will not be able to save and load your scripts. To generate a new UUID, use Online UUID Generator or any other tool that can generate UUIDs. ComponentProvider - gives access to inner fields of the script marked with #[component(include)] attribute. #[visit(optional)] attribute is used to suppress serialization errors when some fields are missing or changed. 4.3.3 Script Template Generator You can use fyrox-template tool to generate all required boilerplate code for a new script, it makes adding new scripts much less tedious. To generate a new script use script command: fyrox-template script --name MyScript It will create a new file in game/src directory with my_script.rs name and fill with required code. Do not forget to add the module with the new script to lib.rs like this: // Use your script name instead of `my_script` here. pub mod my_script; Comments in each generated method should help you to figure out which code should be placed where and what is the purpose of every method. ⚠️ Keep in mind that every new script must be registered in PluginConstructor::register, otherwise you won’t be able to assign the script in the editor to a node. See the next section for more info. 4.3.4 Script Registration Every script must be registered before use, otherwise the engine won’t “see” your script and won’t let you assign it to an object. PluginConstructor trait has register method exactly for script registration. To register a script you need to register it in the list of script constructors like so: {{#include ../code/snippets/src/scripting/example.rs:register}} Every script type (MyScript in the code snippet above, you need to change it to your script type) must be registered using ScriptConstructorsContainer::add method, which accepts a script type as a generic argument and its name, that will be shown in the editor. The name can be arbitrary, it is used only in the editor. You can also change it at any time, it won’t break existing scenes. 4.3.5 Script Attachment To assign a script and see it in action, run the editor, select an object and find Scripts property in the Inspector. Click on a small + button and select your script from the drop-down list on the newly added entry. To see the script in action, click “Play/Stop” button. The editor will run your game in separate process with the scene active in the editor. The script can be attached to a scene node from code: {{#include ../code/snippets/src/scripting/example.rs:add_my_script}} Initialization as well as update of newly assigned script will happen on next update tick of the engine. 4.3.6 Script Context Script context provides access to the environment that can be used to modify engine and game state from scripts. Typical content of the context is something like this: {{#include ../code/snippets/src/scripting/context.rs:context}} dt - amount of time passed since last frame. The value of the variable is implementation-defined, usually it is something like 1/60 (0.016) of a second. elapsed_time - amount of time that passed since start of your game (in seconds). plugins - a mutable reference to all registered plugins, it allows you to access some “global” game data that does not belong to any object. For example, a plugin could store key mapping used for player controls, you can access it using plugins field and find desired plugin. In case of a single plugin, you just need to cast the reference to a particular type using context.plugins[0].cast::&lt;MyPlugin&gt;().unwrap() call. handle - a handle of the node to which the script is assigned to (parent node). You can borrow the node using context.scene.graph[handle] call. Typecasting can be used to obtain a reference to a particular node type. scene - a reference to parent scene of the script, it provides you full access to scene content, allowing you to add/modify/remove scene nodes. scene_handle - a handle of a scene the script instance belongs to. resource_manager - a reference to resource manager, you can use it to load and instantiate assets. message_sender - a message sender. Every message sent via this sender will be then passed to every ScriptTrait::on_message method of every script. message_dispatcher - a message dispatcher. If you need to receive messages of a particular type, you must subscribe to a type explicitly. task_pool - task pool for asynchronous task management. graphics_context - Current graphics context of the engine. user_interfaces - a reference to user interface container of the engine. The engine guarantees that there’s at least one user interface exists. Use context.user_interfaces.first()/first_mut() to get a reference to it. script_index - index of the script. Never save this index, it is only valid while this context exists! 4.3.7 Execution order Scripts have strictly defined execution order for their methods (the order if execution is linear and do not depend on actual tree structure of the graph where the script is located): on_init - called first for every script instance on_start - called after every on_init is called on_update - called zero or more times per one render frame. The engine stabilizes update rate of the logic, so if your game runs at 15 FPS, the logic will still run at 60 FPS thus the on_update will be called 4 times per frame. The method can also be not called at all, if the FPS is very high. For example, if your game runs at 240 FPS, then on_update will be called once per 4 frames. on_message - called once per incoming message. on_os_event - called once per incoming OS event. on_deinit - called at the end of the update cycle once when the script (or parent node) is about to be deleted. If a scene node has multiple scripts assigned, then they will be processed as described above in the same order as they assigned to the scene node. 4.3.8 Message passing Script system of Fyrox supports message passing for scripts. Message passing is a mechanism that allows you to send some data (message) to a node, hierarchy of nodes or the entire graph. Each script can subscribe for a specific message type. It is an efficient way for decoupling scripts from each other. For instance, you may want to detect and respond to some event in your game. In this case when the event has happened, you send a message of a type and every “subscriber” will react to it. This way subscribers will not know anything about sender(s); they’ll only use message data to do some actions. A simple example where the message passing can be useful is when you need to react to some event in your game. Imagine, that you have weapons in your game, and they can have a laser sight that flashes with a different color when some target was hit. In very naive approach you can handle all laser sights where you handle all intersection for projectiles, but this adds a very tight coupling between laser sight and projectiles. This is totally unnecessary coupling can be made loose by using message passing. Instead of handling laser sights directly, all you need to do is to broadcast an ActorDamaged { actor: Handle&lt;Node&gt;, attacker: Handle&lt;Node&gt; } message. Laser sight in its turn can subscribe for such message and handle all incoming messages and compare attacker with owner of the laser sight and if the hit was made by attacker flash with some different color. In code this would like so: {{#include ../code/snippets/src/scripting/mod.rs:message_passing}} There are few key parts: You should explicitly subscribe script instance to a message type, otherwise messages of the type won’t be delivered to your script. This is done using the message dispatcher: ctx.message_dispatcher.subscribe_to::&lt;Message&gt;(ctx.handle);. This should be done in on_start method, however it is possible to subscribe/unsubscribe at runime. You can react to messages only in special method on_message - here you just need to check for message type using pattern matching and do something useful. Try to use message passing in all cases, loose coupling significantly improves code quality and readability, however in simple projects it can be ignored completely. 4.3.9 Accessing Other Script’s Data Every script “lives” on some scene node, so to access a script data from some other script you need to know a handle of a scene node with that script first. You can do this like so: {{#include ../code/snippets/src/scripting/mod.rs:access_other_1}} {{#include ../code/snippets/src/scripting/mod.rs:access_other_2}} In this example we have the two script types: MyScript and MyOtherScript. Now imagine that we have two scene nodes, where the first one contains MyScript and the second one MyOtherScript. MyScript knows about the second node by storing a handle of in second_node field. MyScript waits until MyOtherScript will count its internal counter to 60.0 and then prints a message into the log. This code does immutable borrowing and does not allow you to modify other script’s data. If you a mutable access, then use try_get_script_of_mut method (or try_get_script_mut for the alternative code). second_node field of the MyScript is usually assigned in the editor, but you can also find the node in your scene by using the following code: {{#include ../code/snippets/src/scripting/mod.rs:find_node}} This code searches for a node with SomeName and assigns its handle to the second_node variable in the script for later use. 4.4 Tasks Fyrox supports task-based programming for both scripts and plugins. Task is a closure that does something in a separate thread and then the result of it is returned back to the main thread. This is very useful technique, that allows you to perform heavy calculations using all available CPU power, not just one CPU core with a single main thread. Tasks could be used for pretty much anything, that can be done as a separate piece of work. 4.4.1 How it works Main thread spawns a task which is then sent to the task pool. There’s a fixed set of worker threads, that extracts tasks from the task pool when there’s any. Task’s code is then executed in one of the worker thread, which may take any amount of time. When the task is completed, its result is sent to the main thread and then a callback closure is executed to do a desired action on task completion. Usually it’s something relatively fast - for example you may spawn a task that calculates a path on a large navigational mesh and when it is done, you store that path in one of your script instance from which the task was spawned. As you can see, there are two major parts - the task itself and the closure. Graphically it can be represented like this: task Green line represents the main thread and the two purple lines are the worker threads. There could be any number of worker threads, and usually it is a worker thread per each CPU core. Let’s take a look at a typical task path on this image (yellow-ish one). At first, we spawn a task, and it is immediately put in the task pool (in the same thread), after this if we have a free worker thread it extracts our task from the pool and sends it to execution. As you can see any task must implement Send trait, otherwise you’ll get a compilation error. When the task is complete, the worker thread sends the result (again, the result must be Send) to the main thread and an associated callback closure is executed to do something with the result. While the task is being executed, the main thread is not blocked, and it can do other useful stuff. 4.4.2 Examples The following example calculates a path on a navigational mesh in using task-based approach described above. At first, it prepares the “environment” for the task by cloning a shared navigational mesh (Arc&lt;RwLock&lt;NavMesh&gt;&gt;) into a local variable. Then it spawns a new task (async move { .. } block) which reads the shared navigational mesh and calculates a long path, that could take a few frames to compute (imagine a huge island, and we need to get a path from one corner to another). As the last argument to the spawn_script_task method we pass a closure that will be executed on the main thread when the task is complete. It just saves the computed path in the script’s field which is then used for visualization. {{#include ../code/snippets/src/scripting/tasks.rs:script_task}} Plugins could also spawn tasks, which operates on application scale basis, unlike script tasks which operates with separate script instances. A plugin task is a bit easier to use: {{#include ../code/snippets/src/scripting/tasks.rs:plugin_task}} 4.4.3 Performance You should avoid task-based approach for small (in time terms) tasks, because each task has additional cost which might be larger than the actual task executed in-place. This is because you need to send your task to a separate thread using a channel, then the callback closure is stored as a trait object which involves memory allocation. Since tasks uses type erasure technique, they perform dynamic type casting which is not free. Also, there could be any other implementation-defined “slow” spots. A general advice would be: run a profiler first to find hot spots in your game, then try to optimize them. If you hit the optimization limit, use tasks. Do not use tasks until you really need them, try to optimize your game first! If you’re working on a simple 2D game, you’ll never need to use tasks. You might need to use tasks when your have, for instance, a procedurally generated world that should be generated on the fly. For example, if you’re making a dungeon crawler with infinite world. Tasks are also very useful for large games with loads of content and activities. You could off-thread AI, world manipulation (for example if you have a destructible world), etc. In other words - do not use a sledgehammer to hammer nails, unless you have a huge nail. "],["scene-1.html", "Chapter 5 Scene 5.1 Graph 5.2 Transformation 5.3 Prefabs 5.4 Property Inheritance 5.5 Base node 5.6 Mesh node 5.7 Light node 5.8 Sprite 5.9 Particle system 5.10 Terrain 5.11 Camera node 5.12 Exposure and HDR 5.13 Decal node 5.14 Rectangle node 5.15 Custom Scene Node", " Chapter 5 Scene Scene is a container for game entities. Currently, scenes in the engine manage following entities: Graph Animations Physics (rigid bodies, colliders, joints) Sound Scene allows you to create isolated “world” which won’t interact with other scenes, it is very useful for many more or less complex games. 5.0.1 How to create A scene could be created either in FyroxEd or programmatically. You can also combine both approaches, where you build all “static” content in the editor and adding rest of the entities (bots, interactive objects, etc.) manually by instantiating respective prefabs at runtime. 5.0.1.1 Using FyroxEd There is a separate chapter in the book that should help you to create a scene. After a scene is created, you can load it using async scene loader: {{#include ../code/snippets/src/scene/mod.rs:load_scene}} The code is quite straightforward. At first, we’re using async scene loader to create a scene loading request. This request will be processed in a separate thread, leaving your game fully responsible while the scene is loading. Next, when the scene is fully loaded and added to the engine, on_scene_loaded method is called. Usually there’s only one active scene, so we’re removing the previous one and setting the new one as active. There are two additional methods: on_scene_begin_loading - is called when a scene is just began to load. Keep in mind, that async scene loader could load multiple scenes at once and this method is guaranteed to be called exactly before the scene is started to load. on_scene_loading_failed - is called when a scene is failed to load. This method could be useful if you’re using non-verified scenes (i.e. from game mods) and want to react somehow when the scene is failed to load. 5.0.1.2 Create scene manually A scene could also be created manually: {{#include ../code/snippets/src/scene/mod.rs:create_scene}} See respective node builders docs to populate the scene. 5.0.2 Where all my scenes located? All scenes “lives” in the engine, the engine has ownership over your scene after you’ve added it in the engine. You can borrow a scene at any time using its handle and do some changes: {{#include ../code/snippets/src/scene/mod.rs:scene_borrowing}} 5.0.3 Building scene asynchronously You can create your scene in separate thread and then pass it to main thread to insert it in the engine. Why this is needed? Remember the last time you’ve played a relatively large game, you’ve probably noticed that it have loading screens and loading screen has some fancy interactive stuff with progress bar. Loading screen is fully responsive while the game doing hard job loading the world for you. Got it already? Asynchronous scene loading is needed to create/load large scenes with tons of resources without blocking main thread, thus leaving the game fully responsive. 5.0.4 Managing multiple scenes Usually you should have only one scene active (unless you’re making something very special), you should use .enabled flag of a scene to turn it off or on. Deactivated scenes won’t be rendered, the physics won’t be updated, the sound will stop, and so on. In other words the scene will be frozen. This is useful for situations when you often need to switch between scenes, leaving other scene in frozen state. One of the examples where this can be useful is menus. In most games when you’re entering the menu, game world is paused. 5.0.5 Ambient lighting Every scene has default ambient lighting, it is defined by a single RGB color. By default, every scene has some pre-defined ambient lighting, it is bright enough, so you can see your objects. In some cases you may need to adjust it or even make it black (for horror games for instance), this can be achieved by a single line of code: {{#include ../code/snippets/src/scene/mod.rs:set_ambient_lighting}} Please keep in mind that ambient lighting does not mean global illumination, it is a different lighting technique which is not available in the engine yet. 5.1 Graph Graph is a set of objects with hierarchical relationships between each object. It is one of the most important entities in the engine. Graph takes care of your scene objects and does all the hard work for you. 5.1.1 How to create You don’t need to create a graph manually, every scene has its own instance of the graph. It can be accessed pretty easily: scene_ref.graph 5.1.2 Adding nodes There are two ways of adding nodes to the graph, either using node builders or manually by calling graph.add_node. 5.1.2.1 Using node builders Every node in the engine has its respective builder which can be used to create an instance of the node. Using builders is a preferable way to create scene nodes. There are following node builders: BaseBuilder - creates an instance of base node. See Base node for more info. PivotBuilder - creates an instance of pivot node. See Base node for more info. CameraBuilder - creates an instance of camera node. See Camera node for more info. MeshBuilder - creates an instance of mesh node. See Mesh node for more info. LightBuilder - creates an instance of light node. See Light node for more info. SpriteBuilder - creates an instance of sprite node. See Sprite node for more info. ParticleSystemBuilder - creates an instance of particle system node. See Particle system node for more info. TerrainBuilder - creates an instance of terrain node. See Terrain node for more info. DecalBuilder - creates an instance of decal node. See Decal node for more info. RigidBody - creates an instance of rigid body node. See Rigid body for more info. Collider - creates an instance of collider node. See Collider for more info. Joint - creates an instance of joint node. See Joint for more info. Rectangle - creates an instance of 2D rectangle node. See Rectangle for more info. Every builder, other than BaseBuilder, accepts BaseBuilder as a parameter in .new(..) method. Why so? Because every node (other than Base) is “derived” from Base via composition and the derived builder must know how to build Base node. While it may sound confusing, it is actually very useful and clear. Consider this example: {{#include ../code/snippets/src/scene/graph.rs:create_camera}} As you can see, we’re creating an instance of BaseBuilder and fill it with desired properties as well as filling the CameraBuilder’s instance properties. This is a very flexible mechanism, allowing you to build complex hierarchies in a declarative manner: {{#include ../code/snippets/src/scene/graph.rs:create_node}} This code snippet creates a camera for first-person role-playing game’s player, it will have a staff in “right-hand” and a spell in the left hand. Of course all of this is very simplified, but should give you the main idea. Note that staff and fireball will be children nodes of camera, and when setting their transform, we’re actually setting local transform which means that the transform will be relative to camera’s. The staff and the spell will move together with the camera. 5.1.2.2 Adding a node manually For some rare cases you may also want to delay adding a node to the graph, specifically for that purpose, every node builder has .build_node method which creates an instance of Node but does not add it to the graph. {{#include ../code/snippets/src/scene/graph.rs:create_node_manually}} 5.1.3 How to modify the hierarchy For many cases you can’t use builders to create complex hierarchy, the simplest example of such situation when you’re creating an instance of some 3D model. If you want the instance to be a child object of some other object, you should attach it explicitly by using graph.link_nodes(..): {{#include ../code/snippets/src/scene/graph.rs:link_weapon_to_camera}} Here we’ve loaded a weapon 3D model, instantiated it on scene and attached to existing camera. 5.1.4 How to remove nodes A node could be removed by simply calling graph.remove_node(handle), this method removes the node from the graph with all of its children nodes. Sometimes this is unwanted behavior, and you want to preserve children nodes while deleting parent node. To do that, you need to explicitly detach children nodes of the node you’re about to delete: {{#include ../code/snippets/src/scene/graph.rs:remove_preserve_children}} After calling this function, every child node of node_to_remove will be detached from it and the node_to_remove will be deleted. remove_node has some limitations: it cannot be used to extract “sub-graph” from the graph, it just drops nodes immediately. 5.2 Transformation Transformation (transform for short) - is a special entity that changes coordinate system from one to another. It is used primarily in scene nodes to store their position/rotation/scale/pivots/etc. Fyrox has quite complex transformations, that supports: Position (T) Rotation (R) Scale (S) Pre-rotation (Rpre) Post-rotation (Rpost) Rotation Pivot (Rp) Rotation Offset (Roff) Scaling Offset (Soff) Scaling Pivot (Sp) Final transformation matrix will be Transform = T * Roff * Rp * Rpre * R * Rpost * Rp⁻¹ * Soff * Sp * S * Sp⁻¹. In 99.9% cases first three are enough for pretty much every task. Other six components used for specific stuff (mainly for nodes that imported from FBX file format). 5.3 Prefabs A prefab is a separate scene that can be instantiated in some other scene, while preserving links between properties of its instances and of its parent prefab. Prefabs allow you to create a part of a scene and have multiple instances of it in other scenes. Let’s quickly check what that means on practice. The engine has a prefab system which allows you to build hierarchical scenes which can include any number of other scenes as child scenes. Child scenes can have their own child scenes and so on. This is very efficient decoupling mechanism that allows you to put pieces of the scene in separate scenes (prefabs) and modify them independently. The changes in child scenes will be automatically reflected to all parent scenes. Here is the very simple example of why this is important: imagine you need to populate a town with 3D models of cars. Each kind of car has its own 3D model and for example, a collision body that won’t allow the player to walk through cars. How would you do this? The simplest (and dumbest) solution is to copy dozens of car models in the scene, and you’re done. Imagine that now you need to change something in your car, for example, add a trunk that can be opened. What will you do? Of course, you should “iterate” over each car model and do the required changes, you simply don’t have any other option. This will eat huge amount of time and in general it is very non-productive. This is where prefabs will save you hours of work. All you need to do is to create a car prefab and instantiate it multiple times in your scene. When you’ll need to change something in the car, you simply go to the prefab and change it. After that every prefab instance will have your changes! Prefabs can be used to create self-contained entities in your game, examples of this includes: visual effects, any scripted game entities (bots, turrets, player, doors, etc.). Such prefabs can be either directly instantiated in a scene in the editor, or instantiated at runtime when needed. 5.3.1 How to create and use a prefab All you need to do is to make a scene in the editor with all required objects and save it! After that, you can use the scene in other scenes and just do its instantiation, as in usual 3D models. You can either instantiate it from the editor by drag’n’drop a prefab to scene previewer, or do standard model resource instantiation 5.3.2 Property inheritance As already mentioned in the intro section, instances inherit properties from their parent prefabs. For example, you can change position of an object in prefab and every instance will reflect that change - the object’s instances will also move. This works until there’s no manual change to a property in instance, if you do so, your change is considered with higher priority. See this chapter for more info. 5.3.3 Hierarchical Prefabs Prefabs can have other prefab instances inside it. This means that you can, for example, create a room populated with instances of other prefabs (bookshelves, chairs, tables, etc.) and then use the room prefab to build a bigger scene. The changes in the base prefabs will be reflected in their instances, regardless of how deep the hierarchy is. 5.4 Property Inheritance Property inheritance is used to propagate changes of unmodified properties from a prefab to its instances. For example, you can change scale of a node in a prefab and its instances will have the same scale too, unless the scale is set explicitly in an instance. Such feature allows you to tweak instances, add some unique details to them, but take general properties from parent prefabs. Property inheritance works for prefab hierarchies of any depth, this means that you can create something like this: a room prefab can have multiple instances of various furniture prefabs in it, while the furniture prefabs can also be constructed from other prefabs and so on. In this case if you modify a property in one of the prefabs in the chain, all instance will immediately sync their unmodified properties. 5.4.1 How To Create Inheritable Properties It is possible to use property inheritance for script variables. To make a property of your script inheritable, all you need is to wrap its value using InheritableVariable wrapper. {{#include ../code/snippets/src/scene/inheritance.rs:my_script}} The engine will automatically resolve the correct value for the property when a scene with the script is loaded. If your property was modified, then its value will remain the same, it won’t be overwritten by parent’s value. Keep in mind, that the type of the inheritable variable must be cloneable and support reflection. InheritableVariable implements the Deref&lt;Target = T&gt; + DerefMut traits, this means that any access via the DerefMut trait will mark the property as modified. This could be undesired in some cases so InheritableVariable supports special xxx_silent methods that don’t touch the internal modifiers and allows you to substitute the value with some other “silently” - without marking the variable as modified. 5.4.2 Which Fields Should Be Inheritable? Inheritable variables intended to be “atomic” - it means that the variable stores some simple variable (f32, String, Handle&lt;Node&gt;, etc.). While it is possible to store “compound” variables (InheritableVariable&lt;YourStruct&gt;), it is not advised because of inheritance mechanism. When the engine sees inheritable variable, it searches the same variable in a parent entity and copies its value to the child, thus completely replacing its content. In this case, even if you have inheritable variables inside compound field, they won’t be inherited correctly. Let’s demonstrate this in the following code snippet: {{#include ../code/snippets/src/scene/inheritance.rs:complex_inheritance}} This code snippet should clarify, that inheritable fields should contain some “simple” data, and almost never - complex structs. 5.4.3 Editor The editor wraps all inheritable properties in a special widget that supports property reversion. Reversion allows you to drop current changes and take the parent’s property value. This is useful if you want a property to inherit its parent’s value. In the Inspector it looks like this: revert Clicking on the &lt; button will take the value from the parent prefab and the property won’t be marked as modified anymore. In case there is no parent prefab, the button will just drop modified flag. 5.5 Base node Base node is a scene node that stores hierarchical information (a handle to the parent node and a set of handles to children nodes), local and global transform, name, tag, lifetime, etc. It has self-describing name - it is used as a base node for every other scene node (via composition). It has no graphical information, so it is invisible all the time, but it is useful as a “container” for children nodes. 5.5.1 How to create Use the PivotBuilder to create an instance of the Pivot node (remember Base node itself is used only to build other node types): {{#include ../code/snippets/src/scene/base.rs:build_node}} 5.5.2 Building a complex hierarchy To build a complex hierarchy of some nodes, use .with_children() method of the BaseBuilder, it allows you to build a hierarchy of any complexity: {{#include ../code/snippets/src/scene/base.rs:build_complex_node}} Note that when we’re building a Camera instance, we’re passing a new instance of BaseBuilder to it, this instance can also be used to set some properties and a set of children nodes. The “fluent syntax” is not mandatory to use, the above code snipped could be rewritten like this: {{#include ../code/snippets/src/scene/base.rs:build_complex_node_flat}} However, it looks less informative, because it loses the hierarchical view and it is harder to tell the relations between objects. 5.5.3 Transform Base node has a local transform that allows you to translate/scale/rotate/etc. your node as you want to. For example, to move a node at specific location you could use this: {{#include ../code/snippets/src/scene/base.rs:translate_node}} You could also chain multiple set_x calls, like so: {{#include ../code/snippets/src/scene/base.rs:transform_node}} See more info about transformations here. 5.5.4 Visibility Base node stores all info about local visibility and global visibility (with parent’s chain visibility included). Changing node’s visibility could be useful if you want to improve performance by hiding distant objects (however it strongly advised to use level-of-detail for this) or to hide some objects in your scene. There are three main methods to set or fetch visibility: set_visibility - sets local visibility for a node. visibility - returns current local visibility of a node. global_visibility - returns combined visibility of a node. It includes visibility of every parent node in the hierarchy, so if you have a parent node with some children nodes and set parent’s visibility to false, global visibility of children nodes will be false too, even if local visibility is true. This is useful technique for hiding complex objects with lots of children nodes. 5.5.5 Enabling/disabling scene nodes A scene node could be enabled or disabled. Disabled nodes are excluded from a game loop and has almost zero CPU consumption (their global transform/visibility/enabled state is still updated due to limitations of the engine). Disabling a node could be useful if you need to completely freeze some hierarchy and do keep it in this state until it is enabled again. It could be useful to disable parts of a scene with which a player cannot interact to improve performance. Keep in mind, that enabled state is hierarchical like visibility. When you’re disabling a parent node with some children nodes, the children nodes will be disabled too. 5.6 Mesh node Mesh is a scene node that represents a 3D model. This one of the most commonly used nodes in almost every game. Meshes could be easily created either programmatically or be made in some 3D modelling software (like Blender) and loaded in your scene. 5.6.1 Surfaces Surface is a set of triangles that uses the same material. Mesh node could contain zero of more surfaces; each surface contains a set of vertices and indices that binds vertices with triangles. Mesh nodes split into surfaces to be rendered effectively by modern GPUs. 5.6.2 How to create There are basically two ways, how to pick one depends on your needs. In general, using a 3D modelling software is the way to go, especially with tons and tons of free 3D models available online. ⚠️ The engine supports only FBX and GLTF file format for 3D models! To use GLTF, specify gltf feature of the engine in your root Cargo.toml 5.6.2.1 Using a 3D modelling software To create a 3D model, you could use Blender and then export it to FBX file format. To load your 3D model in the game, you should do few simple steps (loading a 3D model does not differ from a prefab instantiation): {{#include ../code/snippets/src/scene/mesh.rs:load_model_to_scene}} This code snippet intentionally omits proper async/await usage (instead it just blocks current thread until model is loading) and error handling. In the real game you should carefully handle all errors and use async/await properly. 5.6.2.2 Creating a procedural mesh A mesh instance could be created from code, such meshes are called “procedural”. They’re suitable for cases when you cannot create a mesh in 3D modelling software. {{#include ../code/snippets/src/scene/mesh.rs:create_procedural_mesh}} As you can see, creating a mesh procedurally requires lots of manual work and not so easy. 5.6.3 Animation Mesh node supports bone-based animation (skinning) and blend shapes. See Animation chapter for more info. 5.6.4 Data Buffers It is possible to access vertex buffer and index buffer of a mesh to either read or write some data there. For example, the following code extracts world-space positions of every vertex of an animated mesh: {{#include ../code/snippets/src/scene/mesh.rs:extract_world_space_vertices}} 5.7 Light node The engine offers complex lighting system with various types of light sources. 5.7.1 Light types There are three main types of light sources: directional, point, and spotlights. 5.7.1.1 Directional light Directional light does not have a position, its rays are always parallel, and it has a particular direction in space. An example of directional light in real-life could be our Sun. Even if it is a point light, it is so far away from the Earth, so we can assume that its rays are always parallel. Directional light sources are suitable for outdoor scenes. A directional light source could be created like this: {{#include ../code/snippets/src/scene/light.rs:create_directional_light}} By default, the light source will be oriented to lit “the ground”. In other words its direction will be faced towards (0.0, -1.0, 0.0) vector. You can rotate it as you want by setting local transform of it while building. Something like this: {{#include ../code/snippets/src/scene/light.rs:create_oriented_directional_light}} 5.7.1.2 Point light Point light is a light source that emits lights in all directions, it has a position, but does not have an orientation. An example of a point light source: light bulb. {{#include ../code/snippets/src/scene/light.rs:create_point_light}} 5.7.1.3 Spotlight Spotlight is a light source that emits lights in cone shape, it has a position and orientation. An example of a spotlight source: flashlight. {{#include ../code/snippets/src/scene/light.rs:create_spot_light}} 5.7.2 Light scattering scattering Spot and point lights support light scattering effect. Imagine you’re walking with a flashlight in a foggy weather, the fog will scatter the light from your flashlight making it, so you’ll see the “light volume”. Light scattering is enabled by default, so you don’t have to do anything to enable it. However, in some cases you might want to disable it, you can do this either while building a light source or change light scattering options on existing light source. Here is the small example of how to do that. {{#include ../code/snippets/src/scene/light.rs:disable_light_scatter}} You could also change the amount of scattering per each color channel, using this you could imitate the Rayleigh scattering: {{#include ../code/snippets/src/scene/light.rs:use_rayleigh_scattering}} 5.7.3 Shadows By default, light sources cast shadows. You can change this by using set_cast_shadows method of a light source. You should carefully manage shadows: shadows giving the most significant performance impact, you should keep the amount of light sources that can cast shadows at lowest possible amount to keep performance at good levels. You can also turn on/off shadows when you need: {{#include ../code/snippets/src/scene/light.rs:switch_shadows}} Not every light should cast shadows, for example a small light that a player can see only in a distance can have shadows disabled. You should set the appropriate values depending on your scene, just remember: the fewer the shadows the better the performance. The most expensive shadows are from point lights, the less, from spotlights and directional lights. 5.7.4 Performance Lights are not cheap, every light source has some performance impact. As a general rule, try to keep the amount of light sources at reasonable levels and especially try to avoid creating tons of light sources in a small area. Keep in mind that the less area the light needs to “cover”, the higher the performance. This means that you can have tons of small light sources for free. 5.8 Sprite Sprite is just a quad mesh that is always facing camera. It has size, color, rotation around “look” axis and a texture. Sprites are useful mostly for projectiles, like glowing plasma, and for things that should always face a camera. ⚠️ It should be noted that sprites are not meant to be used for 2D games, they’re only for 3D. Use Rectangle node if you need 2D sprites. 5.8.1 How to create A sprite instance could be created using SpriteBuilder: {{#include ../code/snippets/src/scene/sprite.rs:create_sprite}} A sprite with a texture could be created by using .with_material method of the builder: {{#include ../code/snippets/src/scene/sprite.rs:create_sprite_with_texture}} Please note, that this code create a material per each sprite. This could be very unoptimal if you’re using tons of sprites at once, share the same material resource across multiple sprites if you can. Otherwise, each sprite will be rendered in a separate draw call and the overall performance will be very low. 5.8.2 Animation See Sprite Animation chapter for more info. 5.8.3 General rules Sprites must not be used to create any visual effects that involve many particles. You should use particle systems for that. Why so? Particles systems are very well optimized for managing huge amounts of particles at the same time, but sprites are not. Each sprite is quite heavy to be used as a particle in particle systems, it has a lot of “useless” info that will eat a lot of memory. 5.9 Particle system Particle system is a scene node that is used to create complex visual effects (VFX). It operates on huge amount of particles at once allowing you to do complex simulation that involves large amount of particles. Typically, particle systems are used to create following visual effects: smoke, sparks, blood splatters, steam, etc. smoke 5.9.1 Basic Concepts Particle system uses single texture for every particle in the system, only Red channel is used. Red channel interpreted as an alpha for all particles. Every particle is affected by Acceleration parameters of the particle system. It defines acceleration (in m/s2) that will affect velocities of every particle. It is used to simulate gravity. 5.9.1.1 Particle Particle is a square (not quadrilateral, this is important) with a texture which is always facing towards camera. It has the following properties: Position - defines a position in local coordinates of particle system (this means that if you rotate a particle system, all particles will be rotated too). Velocity - defines a speed vector (in local coordinates) that will be used to modify local position of the particle each frame. Size - size (in meters) of the square shape of the particle. Size Modifier - a numeric value (in meters per second), that will be added to the Size at each frame, it is used to modify size of the particles. Lifetime - amount of time (in seconds) that the particle can be active for. Rotation - angle (in radians) that defines rotation around particle-to-camera axis (clockwise). Rotation Speed - speed (in radians per second, rad/s) of rotation of the particle. Color - RGBA color of the particle. 5.9.1.2 Emitters Particle system uses emitters to define a set of zones where particles will be spawned, it also defines initial ranges of parameters of particles. Particle system must have at least one emitter to generate particles. Emitter can be one of the following types: Cuboid - emits particles uniformly in a cuboid shape, the shape cannot be rotated, only translated. Sphere - emits particles uniformly in a sphere shape. Cylinder - emits particle uniformly in a cylinder shape, the shape cannot be rotated, only translated. Each emitter have fixed set of parameters that affects initial values for every spawned particle: Position - emitter have its own local position (position relative to parent particle system node), this helps you to create complex particle systems that may spawn particles from multiple zones in space at once. Max Particles - maximum amount of particles available for spawn. By default, it is None, which says that there is no limit. Spawn Rate - rate (in units per second) defines how fast the emitter will spawn particles. Lifetime Range - numeric range (in seconds) for particle lifetime values. The lower the beginning of the range the less spawned particles will live, and vice versa. Size Range - numeric range (in meters) for particle size. Size Modifier Range - numeric range (in meters per second, m/s) for particle size modifier parameter. X/Y/Z Velocity Range - a numeric range (in meters per second, m/s) for a respective velocity axis (X, Y, Z) that defines initial speed along the axis. Rotation Range - a numeric range (in radians) for initial rotation of a new particle. Rotation Speed Range - a numeric range (in radians per second, rad/s) for rotation speed of a new particle. Important: Every range (like Lifetime Range, Size Range, etc.) parameter generates random value for respective parameter of a particle. You can tweak the seed of current random number generator (fyrox::core::thread_rng()) to ensure that generated values will be different each time. 5.9.2 How to create There are multiple ways of creating a particle system, pick one that best suits your current needs. 5.9.2.1 Using the editor The best way to create a particle system is to configure it in the editor, creating from code is possible too (see below), but way harder and may be not intuitive, because of the large amount of parameters. The editor allows you see the result and tweak it very fast. Create a particle system by Create -&gt; Particle System and then you can start editing its properties. By default, new particle system has one Sphere particle emitter, you can add new emitters by clicking + button at the right of Emitters property in the Inspector (or remove by clicking -). Here’s a simple example: particle system Now start tweaking desired parameters, it is hard to give any recommendations of how to achieve a particular effect, only practice matters here. 5.9.2.2 Using the code You can also create particle systems from code (in case if you need some procedurally-generated effects): {{#include ../code/snippets/src/scene/particle_system.rs:create_smoke}} This code creates smoke effect with smooth dissolving (by using color-over-lifetime gradient). Please refer to API docs for particle system for more information. 5.9.2.3 Using prefabs If you need to create particle systems made in the editor, you can always use prefabs. Create a scene with desired particle system and then instantiate it to your scene. 5.9.3 Soft particles Fyrox used special technique, called soft particles, that smooths sharp transitions between particles and scene geometry: soft particles This technique especially useful for effects such as smoke, fog, etc. where you don’t want to see the “edge” between particles and scene geometry. You can tweak this effect using Soft Boundary Sharpness Factor, the larger the value the more “sharp” the edge will be and vice versa. 5.9.4 Restarting emission You can “rewind” particle systems in the “initial” state by calling particle_system.clear_particles() method, it will remove all generated particles and emission will start over. 5.9.5 Enabling or disabling particle systems By default, every particle system is enabled. Sometimes there is a need to create a particle system, but not enable it (for example for some delayed effect). You can achieve this by calling particle_system.set_enabled(true/false) method. Disabled particle systems will still be drawn, but emission and animation will be stopped. To hide particle system completely, use particle_system.set_visibility(false) method. 5.9.6 Performance Particle systems using special renderer that optimized to draw millions of particles with very low overhead, however particles simulated on CPU side and may significantly impact overall performance when there are many particle systems with lots of particles in each. 5.9.7 Limitations Particle systems does not interact with lighting, this means that particles will not be lit by light sources in the scene. 5.10 Terrain Terrain is a scene node that represents uniform grid of cells where each cell can have different height. Other, commonly known name for terrain is heightmap. Terrains used to create maps for open-world games, it is used to create hills, mountains, plateau, roads, etc. terrain 5.10.1 Basic concepts There are few basic concepts that you should understand before trying to use terrains. This will help you to understand design decisions and potential use cases. 5.10.1.1 Heightmap As it was already mentioned, terrain is a uniform grid where X and Z coordinates of cells have fixed values, while Y can change. In this case we can store only width, height and resolution numerical parameters to calculate X and Z coordinates, while Y is stored in a separate array which is then used to modify heights of cells. Such array is called heightmap. terrain mesh 5.10.1.2 Layers Layer is a material + mask applied to terrain’s mesh. Mask is a separate, greyscale texture that defines in which parts of the terrain the material should be visible or not. White pixels in the mask makes the material to be visible, black - completely transparent, everything between helps you to create smooth transitions between layers. Here’s a simple example of multiple layers: terrain layers layout There are 3 layers: 1 - dirt, 2 - grass, 3 - rocks and grass. As you can see, there are smooth transitions between each layer, it is achieved by layer’s mask. Each layer uses separate material, which can be edited from respective property editor in the Inspector: terrain layer material 5.10.2 Creating terrain in the editor You can create a terrain node by clicking Create -&gt; Terrain. It will create a terrain with fixed width, height, and resolution (see limitations). Once the terrain is created, select it in the World Viewer and click on Hill icon on the toolbar. This will enable terrain editing, brush options panel should also appear. See the picture below with all the steps: terrain editing The green rectangle on the terrain under the cursor represents current brush. You can edit brush options in the Brush Options window: brush options You can select a shape (either circle or rectangle with configurable size) and a mode (either modify the height map, or draw on mask of specific layer). When editing terrain’s height, left mouse button raises height map, but if Shift key is pressed it lowers it instead. Something similar is applied to the mask editing - left mouse button draws, but if hold Shift - it will erase mask content. 5.10.3 Creating terrain from code Terrain can always be created from code, here’s comprehensive example of how to create and modify terrain from code: {{#include ../code/snippets/src/scene/terrain.rs:create_random_two_layer_terrain}} As you can see there is quite a lot of code, ideally you should use editor all the times, because handling everything from code could be very tedious. The result of its execution (if all textures are set correctly) could be something like this (keep in mind that terrain will be random every time you run the code): terrain from code 5.10.4 Physics By default, terrains does not have respective physical body and shape, it should be added manually. Create a static rigid body node with a collider with Heightmap shape (learn more about colliders). Then attach the terrain to the rigid body. Keep in mind that terrain’s origin differs from Heightmap rigid body, so you need to offset the terrain to match its physical representation. Enable physics visualization in editor settings to see physical shapes and move terrain. Now to move the terrain you should move the body, instead of the terrain (because of parent-child relations). 5.10.5 Performance Terrain rendering complexity have linear dependency with the amount of layers terrain have. Each layer forces the engine to re-render terrain’s geometry with different textures and mask. Typical amount of layers is from 4 to 8. For example, a terrain could have the following layers: dirt, grass, rock, snow. This is a relatively lightweight scheme. In any case, you should measure frame time to understand how each new layer affects performance in your case. 5.10.6 Chunking Terrain itself does not define any geometry or rendering data, instead it uses one or more chunks for that purpose. Each chunk could be considered as a “sub-terrain”. You can “stack” any amount of chunks from any side of the terrain. To do that, you define a range of chunks along each axis. This is very useful if you need to extend your terrain in a particular direction. Imagine that you’ve created a terrain with just one chunk (0..1 range on both axes), but suddenly you foundthat you need to extend the terrain to add some new game locations. In this case you can change the range of chunks at the desired axis. For instance, if you want to add a new location to the right from your single chunk, then you should change width_chunks range to 0..2 and leave length_chunks as is (0..1). This way terrain will be extended, and you can start shaping the new location. 5.10.7 Level-of-detail Terrain has automatic LOD system, which means that the closest portions of it will be rendered with the highest possible quality (defined by the resolution of height map and masks), while the furthest portions will be rendered with the lowest quality. This effectively balances GPU load and allows you to render huge terrains with low overhead. The main parameter that affects LOD system is block_size (Terrain::set_block_size), which defines size of the patch that will be used for rendering. It is used to divide the size of the height map into a fixed set of blocks using quad-tree algorithm. Current implementation uses modified version of CDLOD algorithm without patch morphing. Apparently it is not needed, since bilinear filtration in vertex shader prevents seams to occur. Current implementation makes it possible to render huge terrains (64x64 km) with 4096x4096 heightmap resolution in about a millisecond on average low-to-middle-end GPU. 5.10.8 Limitations and known issues There is no way to cut holes in the terrain yet, it makes impossible to create caves. There is also no way to create ledges, use separate meshes to imitate this. See tracking issue for more info. 5.11 Camera node Camera is a special scene node that allows you to “look” at your scene from any point and with any orientation. Currently, the engine supports only perspective cameras, which could be represented as a frustum volume. Everything that “intersects” with the frustum will be rendered. Frustum 5.11.1 How to create An instance of camera node could be created using CameraBuilder: {{#include ../code/snippets/src/scene/camera.rs:create_camera}} Orientation and position should be set in BaseBuilder as usual. 5.11.2 Projection modes Projection mode defines how your scene will look like after rendering, there are two projection modes available. 5.11.2.1 Perspective Perspective projection makes distant objects smaller and parallel lines converging when using it, it is the most common projection type for 3D games. By default, each camera uses perspective projection. It’s defined by three parameters that describes frustum volume: Field of view angle Near clipping plane location Far clipping plane location Here is a simple example of how to create a camera with perspective projection: {{#include ../code/snippets/src/scene/camera.rs:create_perspective_camera}} 5.11.2.2 Orthographic Orthographic projection prevents parallel lines from converging, it does not affect object size with distance. If you’re making 2D games or isometric 3D games, this is the projection mode you’re looking for. Orthographic projection defined by three parameters: Vertical Size Near Clipping Plane Far Clipping Plane Vertical size defines how large the “box” will be in vertical axis, horizontal size is derived from vertical size by multiplying vertical size with aspect ratio. Here is a simple example of how to create a camera with orthographic projection: 5.11.3 Performance Each camera forces engine to re-render scene one more time, which can be very resource-intensive (both CPU and GPU) operation. To reduce GPU load, try to keep the Far Clipping Plane at lowest possible values. For example, if you’re making a game with closed environment (lots of corridors, small rooms, etc.) set the Far clipping Plane to max possible distance that can be “seen” in your game - if the largest thing is a corridor, then set the Far clipping Plane to slightly exceed the length. This will force the engine to clip everything that is out of bounds and do not draw such objects. 5.11.4 Skybox Outdoor scenes usually have distant objects that can’t be reached, these can be mountains, sky, distant forest, etc. such objects can be pre-rendered and then applied to a huge cube around camera, it will always be rendered first and will be the background of your scene. To create a Skybox and set it to a camera, you can use the following code: {{#include ../code/snippets/src/scene/camera.rs:create_camera_with_skybox}} 5.11.5 Color grading look-up tables Color grading Look-Up Tables (LUT) allows you to transform color space of your frame. Probably everyone saw the famous “mexican” movie effect when everything becomes yellow-ish when action takes place in Mexico, this is done via color grading LUT effect. When used wisely, it can significantly improve perception of your scene. Here is the same scene having no color correction along with another case that has “mexico” color correction: Scene Look-up-table To use color grading LUT you could do something like this: {{#include ../code/snippets/src/scene/camera.rs:create_camera_with_lut}} 5.11.6 Picking In some games you may need to do mouse picking of objects in your scene. To do that, at first you need to somehow convert a point on the screen to ray in the world. Camera has make_ray method exactly for that purpose: {{#include ../code/snippets/src/scene/camera.rs:make_picking_ray}} The ray then can be used to perform a ray cast over physics entities. This is the simplest way of camera picking, and you should prefer it most of the time. 5.11.6.1 Advanced picking Important: The following picking method is for advanced engine users only, if you don’t know the math you should not use it. If you know the math and don’t want to create physical entities, you can use this ray to perform manual ray intersection check: {{#include ../code/snippets/src/scene/camera.rs:precise_ray_test}} precise_ray_test is what you need, it performs precise intersection check with geometry of a mesh node. It returns a tuple of the closest distance and the closest intersection point. 5.12 Exposure and HDR (WIP) 5.13 Decal node Decal nodes allow you to “project” a texture onto your scene within some specific bounds. It is widely used for bullet holes, blood splatter, dirt, cracks and so on. Here is the example of the decal applied to the scene: Decal The rust marks are applied on existing geometry of the scene by projecting a rust texture in specific direction. 5.13.1 How to create A decal instance can be created using DecalBuilder: {{#include ../code/snippets/src/scene/decal.rs:create_decal}} 5.13.2 Textures You can specify which textures the decal will be projecting, currently there is only diffuse and normal maps supported. 5.13.3 Rendering Currently, the engine supports only deferred decals, which means that decals modify the information stored in G-Buffer. This fact means that decals will be lit correctly with other geometry in the scene. However, if you have some objects in your scene that uses forward rendering path, your decals won’t be applied to them. 5.13.4 Bounds Decal uses Object-Oriented Bounding Box (OOB) to determine pixels on which decal’s textures will be projected, everything that got into OOB will be covered. Exact bounds can be set by tweaking local transform of a decal. If you want your decal to be larger, set its scale to some large value. To position a decal - use local position, to rotate - local rotation. A decal defines a cube that projects a texture on every pixel of a scene that got into the cube. Exact cube size is defined by decal’s local scale. For example, if you have a decal with scale of (1.0, 2.0, 0.1) then the size of the cube (in local coordinates) will be width = 1.0, height = 2.0 and depth = 0.1. The decal can be rotated as any other scene node. Its final size and orientation are defined by the chain of transformations of parent nodes. 5.13.5 Layers There are situations when you want to prevent some geometry from being covered with a decal, to do that the engine offers a concept of layers. A decal will be applied to a geometry if and only if they have matching layer index. This allows you to create environment damage decals, and they won’t affect dynamic objects since they’re located on different layers. 5.13.6 Performance Current implementation of decals is relatively cheap, this allows you to create many decals on scene. However, you should keep the amount of decals at a reasonable level. 5.14 Rectangle node Rectangle is the simplest “2D” node, it can be used to create “2D” graphics. 2D is in quotes here because the node is actually a 3D node, like everything else in the engine. Here is an example scene made with the rectangle nodes and an orthographic camera: 2d scene As you can see it is a good basis for 2D games. 5.14.1 How to create Use the RectangleBuilder to create Rectangle nodes: {{#include ../code/snippets/src/scene/rectangle.rs:create_rect}} 5.14.2 Specifying image portion for rendering By default, Rectangle node uses entire image for rendering, but for some applications it is not enough. For example, you may want to use sprite sheets to animate your 2D entities. In this case you need to be able to use only portion of an image. It is possible to do by using set_uv_rect method of the Rectangle node. Here’s an example of setting right-top quarter of an image to be used by a Rectangle node: {{#include ../code/snippets/src/scene/rectangle.rs:set_2nd_quarter_image_portion}} Keep in mind that every part of uv rectangle is proportional. For example 0.5 means 50%, 1.5 = 150% and so on. If width or height is exceeding 1.0 and the texture being used is set to Wrapping mode at respective axis, the image will tile across axes. 5.14.3 Animation See Sprite Animation chapter for more info. 5.14.4 Performance Rectangles use specialized renderer that is heavily optimized to render tons of rectangles at once, so you can use rectangles almost for everything in 2D games. 5.15 Custom Scene Node Sometimes there is a need to have custom scene nodes, it is possible to do, but it requires quite a lot of boilerplate code. {{#include ../code/snippets/src/scene/custom.rs:custom_node}} Once the node is defined, you can create is as usual and put in the graph: {{#include ../code/snippets/src/scene/custom.rs:add_custom_node}} 5.15.1 Limitations Scene nodes have no access to outer context, this means that you cannot reference any data that is located outside graph easily. You still can define a global variable that will be accessible, but it is considered as a hack and should be avoided. If you want to add custom logic to scene nodes, then you should use scripts instead. Custom nodes are intended for very specific use cases, such as adding “data sources” for renderer, etc. 5.15.2 Editor support For now, you cannot create custom nodes from the editor. This will be available in future versions of the engine. "],["physics-2.html", "Chapter 6 Physics 6.1 Rigid body node 6.2 Collider node 6.3 Joint 6.4 Ray Casting 6.5 Ragdoll", " Chapter 6 Physics The engine have full-featured physics engine under the hood (Rapier), it helps you to simulate physics in your games. There is first-class support for both 2D and 3D physics. There are three main physics entities in the engine: Rigid Body - responsible for rigid body dynamics simulation, must have at least one collider to be able to interact with other rigid bodies in the world. Collider - responsible for collision detection. Joint - responsible for motion restriction between two rigid bodies. All these entities are ordinary scene nodes, so they can be arranged into any hierarchy in the scene. However there some rules that have to be followed to make physics simulation work as intended: Rigid body node must have at least one direct child Collider node, otherwise rigid body won’t interact with other rigid bodies in the world. Joint node must have two direct child rigid bodies, otherwise joint will have no effect. 6.0.1 Differences between 3D and 2D There is a very few differences between 3D and 2D physics, the most obvious is that 2D physics does simulation only in oXY plane (the plane of the screen). 2D physics has less collider shapes available since some 3D shapes degenerate in 2D, for example cylinder 3D shape in 2D is just a rectangle. There is also lesser amount of joints available in 2D, there is no revolute joint for example. Unlike 3D physics entities, 2D physics entities exist in the separate scene::dim2 module. 6.1 Rigid body node Rigid body node is the one of main physical entities in the engine. Rigid body nodes can be affected by gravity, external forces and other rigid bodies. Use rigid body node everywhere you need natural physical behavior for your objects. 6.1.1 How to create Use RigidBodyBuilder to create a rigid body instance: {{#include ../code/snippets/src/scene/rigid_body.rs:create_cube_rigid_body}} 6.1.2 Colliders Rigid body must have at least one collider to participate in simulation properly, multiple colliders can be used to create complex shapes from simple shapes, you can create concave objects this way. Every collider must be a direct child node of a rigid body. In the editor it could look like this: colliders Note that, Box node here is an instance of Rigid Body 2D, and it has Collider 2D as a child and some sprite. This structure (when a rigid body has a collider as a child) is mandatory for physics engine to work correctly! Collider won’t work (participate in physical simulation) without a rigid body and a rigid body won’t work without a collider. This applied to both 2D and 3D. Keep in mind, that your graphical representation of an object (some node like Mesh, Sprite, etc.) must be attached to a rigid body. Otherwise, the rigid body will move, but the graphical representation won’t. You can also arrange it other way around: a graphical node can have rigid body with a collider, but that requires the rigid body to be kinematic. This is used to create hit boxes, or any other things that should have physical representation, but move together with graphical node. 6.1.3 Force and torque You can apply forces and torque to any rigid body, but only dynamic bodies will be affected. There is two ways of applying force to a rigid body: at center of mass or at particular point at the body: {{#include ../code/snippets/src/scene/rigid_body.rs:apply_force_and_torque}} 6.1.4 Kinematic rigid bodies Sometimes you may want to have direct control over position/rotation of a rigid body and tell the physics engine to not do simulation for the body. This can be achieved by making the rigid body kinematic: {{#include ../code/snippets/src/scene/rigid_body.rs:create_kinematic_rigid_body}} 6.1.5 Continuous collision detection Fast-moving rigid bodies can “fly through” other objects (for example a bullet can completely ignore walls if it is moving too fast), this happens because of discrete calculation. This can be fixed by using continuous collision detection, to enable it use either .with_ccd_enabled(state) of RigidBodyBuilder or .set_ccd_enabled(state) of RigidBody. 6.1.6 Dominance Dominance allows you to set a priority of forces applied to rigid bodies. It defines which rigid body can affect what rigid body, for example you can set the highest dominance for actors and leave dominance of everything else at zero, this way actors will be able to push any other dynamic bodies, but dynamic bodies won’t affect actors. This is useful when you don’t want your actors be pushed by surrounding objects (like if someone throws a box at an actor, it will stay still if it has higher dominance) 6.1.7 2D rigid bodies 2D rigid bodies have no difference with 3D, except the simulation happens in oXY plane and Z coordinate is ignored. 6.2 Collider node Collider is a geometrical shape that is used for collision detection, contact manifold generation, etc. Colliders are used in pair with rigid bodies, they make rigid body participate in collisions. Important: Colliders only works in pair with rigid bodies! Colliders won’t be used by the engine, unless they are direct children of a rigid body. Read this chapter for more info. 6.2.1 Shapes Collider can have almost any shape, the engine offers the following shapes for 3D: Ball - dynamic sphere shape. Cylinder - dynamic cylinder shape. Cone - dynamic cone shape. Cuboid - dynamic box shape. Capsule - dynamic capsule shape. Segment - dynamic segment (“line”) shape Triangle - simple dynamic triangle shape Triangle mesh - static concave shape, can be used together with any static level geometry (wall, floors, ceilings, anything else) Height field - static height field shape, can be used together with terrains. Polyhedron - dynamic concave shape. Also, there is a similar, but smaller set for 2D (because some shapes degenerate in 2D): Ball - dynamic circle shape. Cuboid - dynamic rectangle shape. Capsule - dynamic capsule shape. Segment - dynamic segment (“line”) shape. Triangle - dynamic triangle shape. Trimesh - static triangle mesh shape. Heightfield - static height field shape. Dynamic in both lists means that such shapes can be used together with dynamic rigid bodies, they’ll correctly handle all collisions and simulation will look as it should. Static means that such shape should be used only with static rigid bodies. 6.2.2 How to create Use ColliderBuilder to create an instance of collider from code with any shape you want. {{#include ../code/snippets/src/scene/collider.rs:create_capsule_collider}} In the editor you can use MainMenu -&gt; Create -&gt; Physics -&gt; Collider, or right-click on a node in World Viewer and select Add Child -&gt; Physics -&gt; Collider. Collider must be direct child of a rigid body, colliders do nothing on their own! 6.2.3 Collision filtering Sometimes there’s a need to prevent collision between various groups of colliders. Fyrox supports bit-wise collision filtering exactly for this purpose. For instance, you may have two groups of colliders: actors and powerups, and you want the actors to completely ignore collisions with powerups (and vice versa). In this case you can set collision groups for actors like so: actors collision groups And set the collision groups for powerups like so: powerups collision groups As you can see, actors and powerups now have separate memberships (read - groups) and filters. This way, the actors will collide with everything, but powerups and vice versa. 6.2.4 Using colliders for hit boxes You can use colliders to simulate hit boxes for your game characters. It can be done by creating a rigid body with KinematicPositionBased type and an appropriate collider as a child node. As the last step you need to attach the body to a bone in your character’s model. Here’s a quick example from the editor: hitbox As you can see, the rigid body has a capsule collider as a child and the body is attached to the neck bone. The body has KinematicPositionBased type, which will ensure that the body won’t be simulated, instead its position will be synchronized with the position of the parent bone. To actually use the hit boxes in your game, you can either use a ray-casting to perform a hit scan or you can use contacts information to fetch the stuff with which a hit box was contacted. See Ray casting chapter of the section. 6.3 Joint Joint is a configurable link between two rigid bodies, it restricts relative motion of two bodies. Fyrox provides a fixed set of joints that are suitable for various applications. Fixed Joint - hard link between two bodies, it is the same is if two rigid bodies were “welded” to each other with a metal rod. Revolute Joint - restricts all translational movement and any rotations around Y and Z axes, but leaves rotation around local X axis free. An example of the joint from real world is a door hinge, it allows the door to rotate around single axis, but not move. Prismatic Joint - restricts all rotations, movement is allowed along single axis (local X of the joint). An example of the joint from real world could be a slider that supports drawers on a table. Ball Joint - restricts all movement, but leaves rotations unrestricted. An example of a ball joint from real world could be human shoulder. 2D joints does not have revolute joints, because it degenerates into ball joint. 6.3.1 Bodies Binding When the joint is created and all bodies are set to it, it uses self global transform and bodies global transforms to calculate local frames for bodies. This process is called binding, it happens once when the joint is created, but can be initiated by moving the joint to some other position by changing local transform of the joint. 6.3.2 How to create To create a joint from code use JointBuilder: {{#include ../code/snippets/src/scene/joint.rs:create_joint}} Once the joint is created, it will bind given bodies, using the process describe in the above section. To create a joint from editor, use MainMenu -&gt; Create -&gt; Physics -&gt; Joint, select the new joint and find Body1 and Body2 properties. Assign the fields by holding Alt key and drag’n’drop a rigid body to a field. Move the joint to correct position to ensure the binding will happen as intended. 6.3.3 Limits You can restrict motion on primary joint axis (rotational and translational) by setting a limit to desired axis. Ball Joint have three angular limits, one per rotation around an axis. The angle range is given in radians. Prismatic Joint have only one limit it is maximum linear distance between two bodies along primary joint axis. Revolute Joint have a single angular limit around primary axis. The angle range is given in radians. Fixed Joint does not have any limit setting, because it locks all degrees of freedom. 6.3.4 Usage Joints can be used to create many game entities, such as doors, chains and rag dolls. The most interesting here is rag doll. It is used to create realistic behaviour for humans and creatures in games. In general, it is a set of rigid bodies, colliders and joints. Where each joint configured to match joints of a creature, for example ball joint could be used for shoulders, revolute joints for knees and elbows. 6.4 Ray Casting Ray casting allows you to query intersections of a ray with rigid bodies in a scene. Typical usage for ray casting is hit-scan weapons (weapons that shoots high-speed projectiles), AI collision avoidance, etc. To query intersections, use physics world instance of a scene graph: {{#include ../code/snippets/src/scene/ray.rs:do_ray_cast}} The function above will return a collection of intersections that are sorted by intersection distance (a distance from beginning of the ray to an intersection point). Each intersection is represented by the following structure: pub struct Intersection { pub collider: Handle&lt;Node&gt;, pub normal: Vector3&lt;f32&gt;, pub position: Point3&lt;f32&gt;, pub feature: FeatureId, pub toi: f32, } collider - a handle of the collider with which intersection was detected. To obtain a handle to rigid body, borrow the collider and fetch its parent field: graph[collider].parent(). normal - a normal at the intersection position in world coordinates. position - a position of the intersection in world coordinates. feature - additional data that contains a kind of the feature with which intersection was detected as well as its index. FeatureId::Face might have index that is greater than amount of triangles in a triangle mesh, this means that intersection was detected from “back” side of a face. To “fix” that index, simply subtract amount of triangles of a triangle mesh from the value. toi - (time of impact) a distance from ray’s origin to position. 6.4.1 Avoiding unnecessary allocations As you might’ve noticed, the function above return Vec&lt;Intersection&gt; which allocates intersections on heap. This is relatively slow and could be sped up a lot by using static array on stack: {{#include ../code/snippets/src/scene/ray.rs:do_static_ray_cast}} usage_example shows how to use the do_static_ray_cast function - all you need to do is to specify maximum amount of intersections you’re interested in as a generic parameter. 6.5 Ragdoll Ragdoll physics is a sort of procedural animation, that allows you to create naturally looking death animations and body physics in general. Ragdoll is just an arbitrary combination of rigid bodies, colliders, joints. Rigid bodies and colliders define physical “boundaries” for limbs of your character, while joints restrict relative motion (linear and rotational). 6.5.1 How To Create Creating a ragdoll manually is a very tedious procedure, you need to create rigid bodies and colliders for every body part of your character, place them correctly, adjust their size, etc. Then you need to create a set of joints, that connects body parts, and then setup linear and angular limits. To save time, Fyrox has a special tool called Ragdoll Wizard: ragdoll wizard It can be opened from Utils menu and contains quite a lot of node handle fields that needs to be filled. Thankfully, there’s an Autofill button, by pressing which, the wizard will try to find respective bones of the skeleton and put their handles in the respective fields in the wizard. For now, it is configured to work with mixamo skeletons. Other parameters are listed below: Total Mass - total mass of the ragdoll, it will be used to configure masses of rigid bodies of body parts. Use CCD - a flag, that defines whether the continuous collision detection (CCD) for body parts should be used or not. It is advised to keep this flag on, otherwise body parts might get stuck or fall through the floor, leading to “explosive” ragdoll behaviour. Can Sleep - a flag, that defines whether the body parts can “sleep” or not. Sleep in this case means, that a body part can be excluded from physical simulation if it is not moving for some time. Collision Groups and Solver Groups could be used to configure collision filtering. It is very important in case if your character has a physical capsule, that is used to “standard” character physics. In this case body parts must ignore physical capsule (and vice versa), otherwise your ragdoll will “explode”. After everything is filled in, you can click OK button and if everything is correct, you should see a bunch of new scene nodes in the world viewer, located under a Ragdoll scene node: ragdoll result As you can see, the amount of entities you’d have to create and configure manually is quite high. Keep in mind, that ragdoll wizard can’t generate perfect ragdoll, because of lack of information. The generated ragdoll will most likely require some minor tweaks (mostly joint angular limits). 6.5.2 Video Tutorials There’s one video tutorial about ragdoll wizard, it also shows the final results in game: "],["sound-system.html", "Chapter 7 Sound System 7.1 Audio Bus 7.2 Sound 7.3 Head Related Transfer Function", " Chapter 7 Sound System Fyrox has quite powerful and flexible audio system which will be covered in this chapter. Basic “building blocks” are sound sources, sound buffers, audio processing buses with various sound effects, sound context. Read the next chapters to learn more. 7.1 Audio Bus Audio bus is an audio processing unit that takes audio samples from any number of sound sources and passes them through a chain of effects (zero or more). Processed samples then can be either sent to an audio playback device (speakers, headphones, etc.) or to some other audio bus. There’s always one audio bus (primary) that sends its data to an audio playback device, every other audio buses are considered secondary. 7.1.1 Graph As stated above, any audio bus (except primary), can output its audio samples to some other audio bus (primary or secondary). Such relationship forms an audio bus graph: data flow diagram As you can see, there can be any number of sound sources which attached to the respective audio buses. Each audio bus can have any number of effects (such as lowpass, highpass, etc. filtering; reverb effect and more). Finally, each audio bus is connected to some other audio bus. Such complex audio processing structure allows you to create pretty much any sound environment. For example, you can create an audio bus with a reverb effect, that will represent a huge hangar with lots of echoes. Then you attach all sound sources located in this “hangar” to the audio bus and your sound sources will sound more naturally, according to environment. 7.1.2 Effects Audio bus can have zero or more audio processing effects. The effects applied one after another (see the arrows on the picture above). You can set any of the following effects: Attenuation - changes “volume” of input sound samples. Reverb - adds echoes, early and late reflections. Could be used to simulate environment with high reflectivity (hangars, parking lots, etc.) Low Pass Filter - passes all frequencies below the specified cut-off frequency. High Pass Filter - passes all frequencies above the specified cut-off frequency. Band Pass Filter - passes all frequencies in a given range around the specified cut-off frequency. All Pass Filter - shifts phase of the signal by 90 degrees at the specified cut-off frequency. Low Shelf Filter - reduces amplitude of frequencies in a shape like this ̅ _ at the cutoff frequency. High Shelf Filter - reduces amplitude of frequencies in a shape like this _/̅ at the cutoff frequency. 7.1.3 Editor In the editor, audio bus graph is located in the Audio Context panel: audio context Primary audio bus is located at the left of the panel, every other audio bus is located to the right. Each audio bus (except primary) has a dropdown list (at the bottom), that specifies output audio bus. The list of effect is located in the center; it can be edited in the Inspector (right side of the image). To attach a sound source to an audio bus, select in the scene and find Audio Bus property in the Inspector and set it to the name of desired audio bus. 7.2 Sound In Fyrox, sounds are nodes of type Sound, with all the consequent properties and workflows. 7.2.1 How to create There are two major ways to create sound sources: from the editor and from code. 7.2.1.1 From Editor A sound source could be created from Create menu (or from the same menu by right-clicking on a node in the world viewer): create After the source is created, you can select it and start editing its properties: sound Buffer - a sound buffer resource, that will be used as a source of samples. If it is empty, then no sound will be played. Drag’n’drop a sound resource from the Asset Browser here to assign it to the source. Play Once - a flag, that defines whether the engine should automatically delete the sound source node from the scene when it is finished playing. Could be useful for one-shot sounds. Gain - a numeric value in [0..1] range, that defines total volume of the sound source. Keep in mind, that this value sets the volume in linear scale, while physically-correct approach would be to use logarithmic scale. This will be fixed in future versions. Panning - a numeric value in [-1..1] range, that defines how loud audio channels will be. -1 - all the sound will be routed to the left channel, 1 - to the right channel. This option works only with 2D sounds (whose spatial blend factor is 0.0) Status - a switch with three possible states: Stopped, Playing, Paused. By default, every sound source is in stopped state, do not forget to switch it to the Playing state, otherwise you won’t hear anything. Looping - a flag, that defines whether the sound source should be playing infinitely, or not. Looping sound source will never switch their status to Stopped. Pitch - playback speed multiplier. By default, it is 1.0 which means default speed. Max Distance - maximum distance, at which the sound source is affected by distance attenuation (for 3D sounds). By default, it set to max possible value. Lower values could be used to prevent sound source from be silent at certain distance. Rolloff Factor - a numeric value, that defines how fast the volume of the sound source will decay with increasing distance to a listener. Playback Time - desired time from which the playback should start (in seconds). Spatial Blend - a numeric value, that defines blending factor between 2D and 3D sound, where 0.0 - the sound is fully 2D, 1.0 - the sound is fully 3D. By default, the value is 1.0. Audio Bus - a name of an audio bus, that will be used to process the samples from the sound source. By default, it is set to Primary. It should match the name of some audio bus, that will be used in your scene. More info about audio processing could found here. 7.2.1.2 From Code Audio files are loaded using the resource manager: {{#include ../code/snippets/src/scene/sound.rs:load_sound}} Then, the node is built using the standard builder pattern: {{#include ../code/snippets/src/scene/sound.rs:build_sound_node}} There are a few notable things in the example above. The first is that sounds don’t play automatically; in order to do so, we need to invoke .with_status(Status::Playing). The second is that sound nodes are not dropped automatically after playback; dropping it can be performed in two ways. One way is to use the convenient builder API .with_play_once(true); another is to use the graph APIs: {{#include ../code/snippets/src/scene/sound.rs:sound_removal}} If we want to play background music (or anyway a repeated sound), we just set the looping property when building the node: {{#include ../code/snippets/src/scene/sound.rs:looping}} In order to stream large audio files, instead of loading them entirely in memory, the simplest strategy is to create a corresponding .options file, with the following content: ( stream: true ) If the audio file is called, for example, /path/to/background.ogg, call this /path/to/background.ogg.options. 7.2.2 2D and 3D There’s no strict separation between 2D and 3D sound sources. The same source could be switched from 2D to 3D (and vice versa) at runtime, by just adjusting Spatial Blend property. Spatial blend factor is a numeric value, that defines blending factor between 2D and 3D sound, where 0.0 - the sound is fully 2D, 1.0 - the sound is fully 3D. By default, the value is 1.0 which makes it 3D. Intermediate values could be used to create “ambisonic” sound sources - when the source sounds like it is placed at some position in the world, but some part of it is just 2D and does not depend on positioning. 7.2.3 Audio bus It is possible to specify target audio bus to which the sound will output its audio samples. Audio bus is responsible for various audio processing, such as filtering, reverb, etc. To specify output audio bus, just use the set_audio_bus method and set the name of an audio bus. 7.3 Head Related Transfer Function Head Related Transfer Function (HRTF for short) is special audio processing technique that improves audio spatialization. By default, sound spatialization is very simple - volume of each audio channel (left and right) changes accordingly to orientation of the listener. While this simple and fast, it does not provide good audio spatialization - sometimes it is hard to tell from which direction the actual sound is coming from. To solve this issue, we can use head-related transfer function. Despite its scary, mathematical name, it is easy to understand what it’s doing. Instead of uniformly changing volume of all frequencies of the signal (as the naive spatialization does), it changes them separately for each channel. The exact “gains” of each frequency of each channel is depends on the contents of head-related transfer function. This is done for each azimuth and elevation angles, which gives full picture of how audio signal from each direction travels to each ear. HRTF is usually recorded using a head model with ears with a microphone inside each ear. To capture head-related impulse response (time domain) at a fixed distance and angle pair (azimuth and elevation), a very short impulse of sound is produced. Microphones inside each ear records the signal, and then HRIR (time domain) can be converted in HRTF (frequency domain). 7.3.1 HRTF on practice The theory above could be boring, however it is very simple to use HRTF on practice. Pick a HRIR sphere from the database (any of *.bin files) and load it in the Audio Context panel: hrtf Once it is loaded, all sounds in the scene will use the HRTF for rendering. The same can be achieved by code: # extern crate fyrox; # use fyrox::scene::{ # graph::Graph, # sound::{self, HrirSphere, HrirSphereResource, HrirSphereResourceExt, HrtfRenderer, Renderer}, # }; # fn use_hrtf(graph: &amp;mut Graph) { let hrir_sphere = HrirSphereResource::from_hrir_sphere( HrirSphere::from_file(&quot;path/to/hrir.bin&quot;, sound::SAMPLE_RATE).unwrap(), &quot;path/to/hrir.bin&quot;.into()); graph .sound_context .state() .set_renderer(Renderer::HrtfRenderer(HrtfRenderer::new(hrir_sphere))); } 7.3.2 Performance HRTF is heavy. It is 5-6 times slower than the simple spatialization, so use it only on middle-end or high-end hardware. HRTF performance is linearly dependent on the amount of sound sources: the more sound sources use HRTF, the worse performance will be and vice versa. "],["animation-4.html", "Chapter 8 Animation 8.1 Animation Editor 8.2 Animation Blending 8.3 Animation Blending State Machine (ABSM) Editor 8.4 Signals 8.5 Root Motion 8.6 Sprite Animation", " Chapter 8 Animation Animation allows you to change properties of scene nodes at runtime using a set of key frames. Animation consists of multiple tracks, where each track is bound to a property of a scene node. A track can animate any numeric properties, starting from numbers (including bool) end ending by 2/3/4 dimensional vectors. Each component (number, x/y/z/w vector components) is stored in a parametric curve. Every parametric curve contains zero or more key frames. Graphically this could be represented like so: Timeline v Time &gt; |---------------|------------------------------------&gt; | | Track1 &gt; | node.position | | X curve |..1..........5...........10.......... | Y curve |..2.........-2..................1.... &lt; Curve key frames | Z curve |..1..........9......................4 |_______________| Track2 | node.property | | ............ |..................................... | ............ |..................................... | ............ |..................................... Each key frame is just a real number with interpolation mode. Interpolation mode tells the engine how to calculate intermediate values between key frames. There are three kinds of interpolation used in animations (you can skip “boring math” if you want): Constant - intermediate value will be calculated using leftmost value of two. Constant “interpolation” is usually used to create step-like behaviour, the most common case is to “interpolate” two boolean values. Linear - intermediate value will be calculated using linear interpolation i = left + (right - left) / t, where t = (time_position - left) / (right - left). t is always in 0..1 range. Linear interpolation is usually used to create “straight” transitions between two values. Cubic - intermediate value will be calculated using Hermite cubic spline: i = (2t^3 - 3t^2 + 1) * left + (t^3 - 2t^2 + t) * left_tangent + (-2t^3 + 3t^2) * right + (t^3 - t^2) * right_tangent, where t = (time_position - left) / (right - left) (t is always in 0..1 range), left_tangent and right_tangent is usually a tan(angle). Cubic interpolation is usually used to create “smooth” transitions between two values. 8.0.1 Web Demo You can explore animation system capabilities in this web demo. Keep in mind, that it was designed to run on PC and wasn’t tested on mobile devices. 8.0.2 Track binding Each track is always bound to a property in a node, either by its name or by a special binding. The name is used to fetch the property using reflection, the special binding is a faster way of fetching built-in properties. It is usually used to animate position, scale and rotation (these are the most common properties available in every scene node). 8.0.3 Time slice and looping While key frames on the curves can be located at arbitrary position in time, animations usually plays a specific time slice. By default, each animation will play on a given time slice infinitely - it is called animation looping, it works in both playback directions. 8.0.4 Speed You can vary playback speed in wide range, by default every animation has playback speed multiplier set to 1.0. The multiplier tells how faster (&gt;1) or slower (&lt;1) the animation needs to be played. Negative speed multiplier values will reverse playback. 8.0.5 Enabling or disabling animations Sometimes there’s a need to disable/enable an animation or check if it is enabled or not, you can do this by using the pair of respective methods - Animation::set_enabled and Animation::is_enabled. 8.0.6 Signals Signal is a named marker on specific time position on the animation timeline. Signal will emit an event if the animation playback time passes signal’s position from left-to-right (or vice versa depending on playback direction). Signals are usually used to attach some specific actions to a position in time. For example, you can have a walking animation and you want to emit sounds when character’s feet touch ground. In this case you need to add a few signals at times when each foot touches the ground. After that all you need to do is to fetch animation events one-by-one and emit respective sounds. See respective chapter for more info. 8.0.7 Creating From Code Usually, animations are created from the editor or some external tool and then imported in the engine. Before trying the example below, please read the docs for AnimationPlayer node, it is much more convenient way of animating other nodes. The node can be created from the editor, and you don’t even need to write any code. Use the following example code as a guide only if you need to create procedural animations: {{#include ../code/snippets/src/animation/mod.rs:create_animation}} The code above creates a simple animation that moves a node along X axis in various ways. The usage of the animation is only for the sake of completeness of the example. In the real games you need to add the animation to an animation player scene node, and it will do the job for you. 8.0.8 Importing It is also possible to import an animation from external source (such as FBX files). You can do this in two major ways: from code or from the editor. The following sections shows how to use both ways. 8.0.8.1 From Editor At first, make sure that you have your 3D model instantiated in the scene. The following example has agent.fbx instance in the scene (to do that, just drag’n’drop your 3D model in the scene from the Asset Browser). To import an animation you need to create an Animation Player scene node, open the Animation Editor and click the button with arrow-down icon: Step 1 Now you need to pick the root node of your 3D model to which you’ll import your animation. Usually it will be called the same as your 3D model (agent.fbx on the screenshot below): Step 2 The last thing you need to do is to pick the animation you want to import: Step 3 If everything is correct, you can preview your animation by clicking Preview checkbox: Step 4 8.0.8.2 From Code You can do the same as in the previous section, but from code: {{#include ../code/snippets/src/animation/mod.rs:create_animated_character}} As you can see, at first this code creates an instance of a 3D model. Then it loads an animation and creates its instance in the animation player. Please note, that this code uses async, which produces a future which should be driven by some executor. You can use block_on method to execute it at call site (this won’t work on WebAssembly). It is advised to prefer the editor to code approach, because it hides all this tedious code and properly handles asynchronous loading on all platforms. 8.0.9 Playing an Animation Animations will be played automatically if the respective animation player is has the property Auto Apply set to true. Since the animation player can contain multiple animations, all of them will be played at once. You can enable/disable animations when needed by finding them by name from code and switching Enabled property: {{#include ../code/snippets/src/animation/mod.rs:enable_animation}} This code could also be used to change animation properties at runtime. To do that, replace set_enabled with some other methods, such as set_speed, set_loop, set_root_motion_settings etc. 8.1 Animation Editor anim editor Animation Editor is a tool that helps you to create and preview animations. This is a powerful tool that can be used to animate pretty much any numeric property. It has three main parts: Toolbar - contains a set of tools that changes a particular part of an animation (name, length, speed, etc.) Track List - contains a list of tracks of nodes that will be animated. Curve Editor - curve editor allows you to edit behaviour of a numeric parameter over the time. The editor can be opened in two ways - using Utils -&gt; Animation Editor or by selecting an animation player node and clicking Open Animation Editor button in the inspector. open1 open2 In both ways you still need to select an animation player for editing. 8.1.1 Typical Workflow At first, you need to create or import an animation, then you need to set its time slice to desired range (see Time Slice in the section below), then you need to add a few tracks for desired properties and finally add some keys. You can preview the results at any time, keep in mind that any attempt to change an animation while it is the preview mode, will revert every change from the preview mode and only then apply your change. 8.1.2 Toolbar The toolbar contains a set of tools that changes a particular part of an animation (name, length, speed, etc.). It looks like this: toolbar Animation Name - name of a currently selected animation. Add Animation - adds a new empty animation with the name from the text box at the left to the animation player. Import Animation - starts animation importing process. See Animation Importing section for more info. Reimport Animation - re-imports the animation from an external file, it is useful if you need to change animation’s content, while keep references to it valid. Rename Animation - renames a currently selected animation using the name from the text box at the left. Animation Selector - allows you to switch currently edited animation. Delete Animation - deletes a currently selected animation, tries to select last animation from the list if possible. Duplicate Animation - clones a currently selected animation. Loop Animation - enables or disables looping of a currently selected animation. Enable Animation - enables or disables a currently selected animation. Animation Speed - sets a new playback speed of a currently selected animation. Time Slice - a time range (in seconds) which defines start and end time of a currently selected animation. The range is highlighted in the curve editor. Root Motion - open root motion settings. See Root Motion section for more info. Preview Switch - enables or disables animation preview. See Preview Mode section for more info. Play/Pause - plays or pauses a currently selected animation (allowed only in the preview mode). Stop - stops a currently selected animation (allowed only in the preview mode). 8.1.3 Track List The track list contains a list of tracks of nodes that will be animated. It looks like this: track list Filter Bar - filters the track list by finding tracks whose names matching the filter. You can use this to find tracks that belong to a particular scene node. Clear Filter - clears the filter, the track list will show all the tracks after this. Collapse All - collapses all the tracks in the list. Expand All - expands all the tracks in the list. Track - a track with some number of children parametric curves. Track Component Curve - parametric curve that serves a data source for the animation for a particular track. Track Switch - enables or disables a track; disabled tracks won’t “touch” their properties. Add Track - starts property binding process, see Property Binding section for more info. 8.1.3.1 Track Context Menu context menu Remove Selected Tracks - removes selected tracks; you can remove multiple tracks at a time by selecting them while holding Ctrl. 8.1.4 Curve Editor Curve editor allows you to edit parametric curves (one at a time). A curve consists of zero or more key frames with various transition rules between current and the next. The editor looks like this: curve editor Time Ruler - shows time values and every signal of a currently selected animation. A click on the time ruler will move the playback cursor at the click position. You can move it by clicking at the cursor and moving the mouse while holding the left mouse button. Animation signals can be moved in the same fashion. Parametric Curve - a curve that defines how a value changes over time. Time Thumb - animation playback cursor, useful only for preview. Animation Signal - some animation signal that will produce animation events when the playback cursor passes it. 8.1.4.1 Time Ruler Context Menu time ruler context menu Remove Signal - removes an animation signal under the mouse cursor. Add Signal - adds a new animation signal at the mouse cursor position. 8.1.4.2 Key Frame Context Menu key frame context menu Location - shows a key location and allows you to change it. Useful for setting precise values. Value - shows a key value and allows you to change it. Useful for setting precise values. Add Key - adds a new key to the curve. Remove - removes all selected keys. You can select multiple keys either by box selection (click and drag the mouse to active box selection) or by clicking on separate keys while holding Ctrl. Key... - allows you to change the interpolation type of key. It could be one of the following values: Constant, Linear, Cubic. Zoom To Fit - tries to find zooming values (for both axes) and the view position with which the entire curve fits in the viewport. 8.1.5 Property Binding To animate a property all you need to do is to click on Add Track... button at the bottom of the track list, select a node to animate and then select a property that will be animated. There are two windows that will be shown one after another: step1 step2 You can cancel property binding at any time by clicking Cancel in any of the windows. Keep in mind that you can animate only numeric properties, so not every property is shown in the window. 8.1.6 Animation Importing Animations can be stored in separate files, but the engine requires all of them to be in a single Animation Player. To put an animation from an external resource (an FBX, for instance) in the animation player you can use animation importing. To do that, click on animation import icon and then select a root node of the hierarchy that is animated in the external animation file, then select the animation file and click Ok. The engine will try to import the animation and map it to the given hierarchy, mapping is done using node names, so animated node names must match in both your scene and your external animation file. step1 step2 Content of existing animations can be replaced by reimporting. Click on a button with two circular arrows to reimport your animation. It could be useful if you changed your animation in some external editor (Blender for example) and want to apply changes in your game. 8.1.7 Preview Mode Preview mode helps you to see and debug your animation. After activating the mode, you need to play the animation by clicking the Play/Pause button: anim editor Any significant change made in the scene will automatically deactivate the preview mode reverting all the changes made by playing animation. 8.1.8 Root Motion See Root Motion chapter for more info. 8.1.9 Limitations For now there’s no dopesheet mode in the editor, you can edit only one numeric parameter at a time. Also, there’s no capture mode - this is a special mode in which the editor automatically adds your changes in the scene to the animation. These limitations will be removed in the future versions. 8.2 Animation Blending Animation blending is a powerful feature that allows you to mix multiple animations into one. Each animation is mixed with a various weights which in sum gives 1.0 (100%). By having opposite coefficients (k1 = 0 -&gt; 1, k2 = 1 -&gt; 0) changing in time it is possible to create transition effect. Handling transitions with all the coefficients is a routine job, the engine can handle it for you giving you some nice features: Multiple states with smooth transitions between them Ability to blend multiple animations in one and use it as pose source for blending Ability to specify a set of variables that will be used as blending coefficients and transition rules. All these features consolidated in so-called animation blending state machine (ABSM). Machine is used to blend multiple animation as well as perform automatic “smooth” transition between states. In general, ABSM could be represented like this: ABSM Structure At the first look it may seem very complicated, but in reality it uses quite simple techniques. Let’s start from the left side of the picture and go to the right. Yellow rectangle at the left depicts an animation player node that contains a bunch of animations, that will be used for blending. Two center blocks (layer 0 and layer 1) depicts separate layers (ABSM could have any number of layers in it). Each layer can contain an arbitrary nodes (green shapes), states (blue shapes), transitions (thick yellow arrows). Nodes serves as a source of poses, that can be blended in any desired way. States are the part of the inner state machine, only one state could be active at the same time. Transitions are used to specify state transition rules. At the “exit” of each layer there’s a layer filter, it is responsible for filtering out values for specific scene nodes and could be used to prevent some scene nodes from being animated by a certain layer. Please note that despite the look of it, layer filter not necessarily be applied after all animations and states are blended - it could be done at any moment and drawn like so only for simplicity reasons. The last, but not the least, important thing on the picture is the parameters container on the right side of the picture. Parameter either a transition rule, blending weight, or sampling point. If you look closely at the transitions or animation blending nodes you’ll see small text marks. This is the names of the respective parameters. In general, any state machine works like this - ABSM nodes are used to blend or fetch animations and their resulting poses are used by ABSM states. Active state provides final pose, which is then passes filtering and returned to you. After the last stage, you can apply the pose to a scene graph to make the resulting animation to have effect. 8.2.1 How to create As always, there are two major ways of creating things in Fyrox - from the editor or from code. Take your pick. 8.2.2 From editor Use ABSM Editor for to create animation blending state machines. 8.2.3 From code You can always create an ABSM from code, a simple ABSM could be created like this: {{#include ../code/snippets/src/animation/blending.rs:create_absm}} Here we have Walk, Idle and Run states which use different sources of poses: - Walk - is the most complicated here - it uses result of blending between Aim and Walk animations with different weights. This is useful if your character can only walk or can walk and aim at the same time. Desired pose determined by Walk Weight and Aim Weight parameters combination. - Run and idle both directly use animation as pose source. There are four transitions between three states each with its own rule. Rule is just a boolean parameter that indicates that transition should be activated. Let’s look at the code example of the above state graph: As you can see, everything is quite straightforward. Even such simple state machine requires quite a lot of code, which can be removed by using ABSM editor. Read the next chapter to learn about it. 8.3 Animation Blending State Machine (ABSM) Editor While it is possible to create and manage animation blending and state manually from code, it quickly becomes too annoying and hardly manageable. To help you create and manage blending machines in easy way, the engine offers an ABSM Editor tool. This chapter is an overview of the editor, it is quite complex, but the guide should help you to figure out which part is made for what. Next chapter will help you to create your first animation blending state machine. absm editor The editor has four main parts (panels): Toolbar - contains a set of tools to edit animation layers and enable/disable preview mode. See Toolbar section for more info. Parameters - allows you to edit various variables that are responsible for transitions, weight parameters for blending, etc. See Parameters section for more info. State Graph - allows you to create, delete, edit states and transition between them. See State Graph section for more info. State Viewer - allows you to edit pose source for a state. Pose source can be represented either by a single node that plays an animation, or a series of play animation nodes connected to blending nodes (which can be connected to other blending nodes, etc.). See State Viewer section for more info. The editor can be opened in two ways - using Utils -&gt; ABSM Editor or by selecting an animation blending state machine node and clicking Open ABSM Editor... button: open1 open1 In both ways you still need to select an an animation blending state machine node for editing. 8.3.1 Toolbar toolbar Preview Switch - enables or disables preview mode for the ABSM. See Preview Mode section for more info. Layer Name - name of the selected layer. Type a new name here to rename currently selected layer (hit enter or just click elsewhere to rename). Add Layer - adds a new layer with the name in the Layer Name text box to the ABSM. ABSM can have multiple layers with the same name, but it strongly advised to set unique names here. Remove Current Layer - removes currently selected layer. You can delete all layers, but in this case your ABSM won’t have any effect. Layer Selector - allows you to select a layer for editing, default selection is none. Layer Mask - opens a Layer Mask Editor and helps you to edit the layer mask of the current layer. See Layer Mask section for more info. 8.3.2 Parameters Parameter is a named and typed variable that provides the animation system with some data required for it to work. There are only three type of parameters: Rule - boolean value that used as a trigger for transitions. When transition is using some rule, it checks the value of the parameter and if it is true transition starts. Weight - real number (f32) that is used a weight when you’re blending multiple animations into one. Index - natural number (i32) that is used as an animation selector. parameters Add Parameters - adds a new parameter to the parameters’ container. Remove a Parameter - removes selected parameter from the parameters’ container. Parameter Name - allows you to set a parameter name. Parameter Type - allows you to select the type of the parameter. Parameter Value - allows you to set parameter value. 8.3.3 State Graph State Graph allows you to create states and transitions between them. state graph State - state is final animation for a set of scene nodes, only one state can be active at a time. Transition - is an ordered connection between two states, it defines how much time it needed to perform blending of two states. Root State - is an entry state of the current layer. 8.3.3.1 State Context Menu state context menu Create Transition - starts transition creation from the current state to some other. Remove - removes the state. Set As Entry State - marks the state as an entry state (this state will be active at beginning). 8.3.3.2 Transition Context Menu transition context menu Remove Transition - removes selected transition. 8.3.3.3 State Properties Select a State node to edit the following properties: state properties Position - is a location of the state on the canvas. Name - name of the state. Root - handle of the backing animation node inside the state. 8.3.3.4 Transition Properties Select a Transition node to edit the following properties: transition properties Name - name of the state. Transition Time - amount of time for blending between two states (in seconds). Elapsed Time - starting amount of blending time. Source - handle of a source state. Desc - handle of a destination state. Rule - a name of Rule type parameter that defines whether the transition can be activated or not. Invert Rule - defines whether to invert the value of Rule or not. Blend Factor - defines a percentage (in 0..1 range) of how much transition was active. 8.3.4 State Viewer State Viewer allows you to edit contents of states. You can create animation blending chains of any complexity, the simplest content of a state is just a single Play Animation node. Currently, the engine supports just three animation blending nodes: Play Animation - takes animation pose directly from specified animation, does nothing to it. Blend Animations - takes multiple animation poses from respective animations and blends them together with respective blend weights. Blend Animations By Index - takes multiple animation poses from respective animations and switches between them with “smooth” transition using an index parameter. state viewer Node - is a source of animation for blending. Connection - defines how nodes are connected to each other. To create a new connection, click on a small dot on a node, hold the button and start dragging to a dot on some other node. Root Node - root node is marked green; root node is a final source of animation for the parent state. 8.3.4.1 Play Animation Properties Select a Play Animation node to edit the following properties: play animation properties Position - is a location of the node on the canvas. Animation - an animation to fetch the pose from. 8.3.4.2 Blend Animations Properties Select a Blend Animations node to edit the following properties: blend animations properties Position - is a location of the node on the canvas. Pose Sources - a set of input poses. To add a pose either click on + or +Input on the node itself. Don’t forget to connect some nodes to the new input poses. Weight - a weight of the pose; could be either a constant value or some parameter. 8.3.4.3 Blend Animations By Index Properties Select a Blend Animations By Index node to edit the following properties: blend animations by index properties Position - is a location of the node on the canvas. Index Parameter - a name of an indexing parameter (must be Index type). Inputs - a set of input poses. To add a pose either click on + or +Input on the node itself. Don’t forget to connect some nodes to the new input poses. Blend Time - defines how much time is needed to transition to the pose. 8.3.4.4 Connection Context Menu Every connection has a context menu that can be shown by a right-click on a connection. connection context menu Remove Connection - removes the connection between parent nodes. 8.3.4.5 Node Context Menu Every node has a context menu that can be shown by a right-click on a connection. node context menu Set As Root - sets the node as the final pose source of the parent state. Remove - removes the node from the state. 8.3.5 Layer Mask layer mask Layer mask editor allows you to select which nodes won’t be animated by the current animation layer. Selected nodes are marked with dark color. To select multiple nodes at once, hold Ctrl and click on items. The text box at the top of the window allows you to search for a particular scene node. To save edited layer mask click OK. 8.3.6 Preview Mode Preview mode turns on the animation blending state machine and its animation player and allows you to see the result of the work of the machine. Any significant changes in the scene automatically disables the preview mode and any changes done by the machine is discarded. While the preview mode is active, you can freely change the values of the parameters to see how the machine will react to this. This helps you to debug your state machine, it is especially useful for complex state machines with lots of layers. Here’s how the preview mode works: absm 8.4 Signals In some cases you may need to perform an action when at certain time of your animation. It could be a footstep sound, when foot touches ground, grenade tossing, etc. This could be done via animation signals. Animation signal is just a named marker that has time position at an animation timeline. It will be emitted when animation playback time passes it (left-to-right or right-to-left depending on the actual speed of your animation). All you need to do, is to catch these signals in your game code and do the desired actions. 8.4.1 How to add As usual, there are two possible ways of adding animation signals - from the animation editor and from code. 8.4.1.1 From animation editor To add a signal to some animation, select an animation player, open the animation editor, select some animation in it. Now all you need to do is to right-click on the timeline and press Add Signal. Add Signal After the signal is added, you can select it and edit its properties in the inspector. Also, you can drag it on the timeline to adjust its position. Edit Signal Set a meaningful name to the signal, and it is pretty much done - all you need to do next is to write signal handling code in your game. See the next section to learn how to do it. 8.4.1.2 From code A signal could also be added from code, this requires knowing a handle of your animation player and a name/handle of your animation. Please note the comment about signal’s uuid in the code below. {{#include ../code/snippets/src/animation/signal.rs:add_signal}} 8.4.2 Reacting to signal events When you have your signals ready for use, all you need to do is to react to the signals somehow. This is very simple: just borrow your animation from the animation player and pop animation event one-by-one from internal queue: {{#include ../code/snippets/src/animation/signal.rs:react_to_signal_events}} You can do pretty much anything when reacting to signals. For example, this could be a prefab instantiation to create smoke effect under the feet, playing a footstep sound, etc. 8.4.3 Events from ABSM Animation blending state machines are able to collect events from the currently playing animations using different strategies. This ability prevents you from tedious manual animation events collection from a bunch of animations manually. {{#include ../code/snippets/src/animation/signal.rs:collect_events_from_absm}} This function collects all animation events from all active animations in the specified ABSM (in its first layer). The arguments to it are the following: absm - a handle to an animation blending state machine node. strategy - event collection strategy, which includes all events collection, max and min weight. The last two may be used if you’re getting a lot of events and want to get events from the animations with max or min weights respectively. ctx - current script context, available in pretty much any script methods. 8.5 Root Motion Root motion is a special technique that transfers motion from some node in a hierarchy to a physical capsule, which is then used to perform the actual motion. In action it looks like this: As you can see in the first part of the video, the movement of the character looks more like floating above the ground. This happens because the actual movement of the physical capsule is not synchronized with the movement of the character. Root motion fixes exactly this issue by taking the motion of some root node of the animated hierarchy (hips in case of this character) and transferring it to the physical capsule. This makes the actual movement to be fully synchronized with the movement “baked” in the animation. Root motion also have some nice effect - you can move your character solely by the movement from animation, and it will work perfectly in 99% of cases. Animations can also contain some rotations which can also be extracted and applied to the physical capsule. The next awesome property is that your character will never stand out of its physical capsule, which will prevent phasing it into walls when playing animations with large movements. In general, you should prefer root motion -driven movement for your characters whenever you can. Simply because it eliminates a lot of common problems with character movement. It can also be applied to 2D world and will work exactly the same. 8.5.1 How to enable You can enable/disable/setup it in the drop-down menu that opens by clicking RM button in the animation editor. Keep in mind, that root motion should be configured on per animation basis. Most of the animations does not need the root motion at all. root motion The most important part here is the Root handle, it should be set to a root node that moves by your animation, usually it is called like “hips” or similar: root node After that, you need to apply filters for axes - most of the locomotion animations “works” in oXZ plane, so Y axis should be ignored. Also, if you don’t have any turns in your animation, you can also filter out the rotation part. Alternatively, you can do the same from code: {{#include ../../code/snippets/src/animation/root_motion.rs:setup_root_motion}} This code does pretty much the same as the editor on the screenshots above. The arguments of this function are the following: animation_player - a handle to the animation player in which all your animations are stored, animation - a handle of the animation in which you want to enable the root motion (you can obtain the handle by using AnimationContainer::find_by_name_ref method). root_node - a handle to a root node of your character’s hierarchy, usually it is called something like “Hips” or “Pelvis”. ctx - script context from your current script. 8.5.2 How to use Direct root motion values extracted from animations are kind of useless by their own and in 99% of the cases you should get the average root motion values from a state machine that animates your character. This is because animation blending state machine properly blends the root motion from all active animation sources. In general, it could look something like this: {{#include ../../code/snippets/src/animation/root_motion.rs:fetch_and_apply_root_motion}} This code extracts the current local-space offset for the current frame and then transforms the offset to world-space coordinates. Finally, it reduces the offset by the current delta time (1.0 / ctx.dt) to obtain the new velocity vector which is then applied to the rigid body (player’s capsule). The arguments in this function are following: absm a handle to an instance of Animation Blending State Machine node rigid_body a handle to the rigid body that is used by your character model - a handle to the root node of your character’s 3D model. 8.5.2.1 Raw root motion values If for some reason you still need raw root motion values from animations, then you can extract them directly from the desired animation by using Animation::root_motion method. 8.5.3 Combining root motion with procedural motion Sometimes there’s a need to combine root motion with some procedural motion (for example - inertia after jumping). This could be done pretty easily by adding two velocity vectors - one from the root motion, and one from the procedural motion. 8.6 Sprite Animation Sprites can be animated using a series of pre-made images. For performance reasons they’re usually packed into a rectangular texture, where each individual image located in its own cell of a grid. Such texture is called a sprite sheet, and it looks something like this: sprite sheet example As you can see, there are multiple frames for each animation (idle, run, sword swing, etc.) packed into a single image. To play an animation, all we need to do is to change frames with some desired frequency and… that’s pretty much all. That’s the simplest animation technique one could imagine. Sprite sheets usually made by artists, not programmers, so just search online for some sprite sheet or order a new one from an artist. Programmer’s art is pretty much always bad. 8.6.1 How to use sprite animation editor Fyrox offers a built-in sprite animation system which has its own editor. To be able to use sprite animation all you need to do is to add a SpriteSheetAnimation field (or a bunch of them) to your script and put the following code in its on_update: {{#include ../../code/snippets/src/animation/mod.rs:animation}} "],["blocks.html", "Chapter 9 Blocks 9.1 Equations 9.2 Theorems and proofs 9.3 Callout blocks", " Chapter 9 Blocks 9.1 Equations Here is an equation. \\[\\begin{equation} f\\left(k\\right) = \\binom{n}{k} p^k\\left(1-p\\right)^{n-k} \\tag{9.1} \\end{equation}\\] You may refer to using \\@ref(eq:binom), like see Equation (9.1). 9.2 Theorems and proofs Labeled theorems can be referenced in text using \\@ref(thm:tri), for example, check out this smart theorem 9.1. Theorem 9.1 For a right triangle, if \\(c\\) denotes the length of the hypotenuse and \\(a\\) and \\(b\\) denote the lengths of the other two sides, we have \\[a^2 + b^2 = c^2\\] Read more here https://bookdown.org/yihui/bookdown/markdown-extensions-by-bookdown.html. 9.3 Callout blocks The R Markdown Cookbook provides more help on how to use custom blocks to design your own callouts: https://bookdown.org/yihui/rmarkdown-cookbook/custom-blocks.html "],["sharing-your-book.html", "Chapter 10 Sharing your book 10.1 Publishing 10.2 404 pages 10.3 Metadata for sharing", " Chapter 10 Sharing your book 10.1 Publishing HTML books can be published online, see: https://bookdown.org/yihui/bookdown/publishing.html 10.2 404 pages By default, users will be directed to a 404 page if they try to access a webpage that cannot be found. If you’d like to customize your 404 page instead of using the default, you may add either a _404.Rmd or _404.md file to your project root and use code and/or Markdown syntax. 10.3 Metadata for sharing Bookdown HTML books will provide HTML metadata for social sharing on platforms like Twitter, Facebook, and LinkedIn, using information you provide in the index.Rmd YAML. To setup, set the url for your book and the path to your cover-image file. Your book’s title and description are also used. This gitbook uses the same social sharing data across all chapters in your book- all links shared will look the same. Specify your book’s source repository on GitHub using the edit key under the configuration options in the _output.yml file, which allows users to suggest an edit by linking to a chapter’s source file. Read more about the features of this output format here: https://pkgs.rstudio.com/bookdown/reference/gitbook.html Or use: ?bookdown::gitbook "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
